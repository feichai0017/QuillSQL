<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>QuillSQL Internals</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">QuillSQL Internals</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>


                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div align="center">
  <img src="assets/rust-db.png" alt="QuillSQL Logo" width="500"/>
</div>
<h1 id="quillsql-internals"><a class="header" href="#quillsql-internals">QuillSQL Internals</a></h1>
<p>Welcome to the technical documentation for QuillSQL.</p>
<p>This book provides a deep dive into the internal architecture and implementation details of the database. It is intended for developers, contributors, and anyone interested in understanding how a relational database is built from the ground up, referencing concepts from classic database courses like CMU 15-445.</p>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li>
<p><a href="./architecture.html"><strong>Overall Architecture</strong></a>: A high-level overview of the entire system.</p>
</li>
<li>
<p><strong>Core Modules</strong></p>
<ul>
<li><a href="./modules/buffer.html"><strong>Buffer Manager</strong></a>: The in-memory page cache.
<ul>
<li><a href="./buffer/page.html">Page &amp; Page Guards</a></li>
<li><a href="./buffer/buffer_pool.html">The Buffer Pool</a></li>
</ul>
</li>
<li><a href="./modules/storage.html"><strong>Storage Engine</strong></a>: How data is physically stored.
<ul>
<li><a href="./storage/disk_io.html">Disk I/O</a></li>
<li><a href="./storage/page_layouts.html">Page &amp; Tuple Layout</a></li>
<li><a href="./storage/table_heap.html">Table Heap &amp; MVCC</a></li>
</ul>
</li>
<li><a href="./modules/index.html"><strong>Indexes</strong></a>: The B+Tree implementation.
<ul>
<li><a href="./index/btree_index.html">B+Tree Details</a></li>
</ul>
</li>
<li><a href="./modules/recovery.html"><strong>Recovery Manager (WAL)</strong></a>: Crash recovery and the ARIES protocol.</li>
<li><a href="./modules/transaction.html"><strong>Transaction Manager</strong></a>: Concurrency control with MVCC and 2PL.</li>
<li><a href="./modules/plan.html"><strong>Query Plan</strong></a>: The journey from SQL to an executable plan.</li>
<li><a href="./modules/optimizer.html"><strong>Query Optimizer</strong></a>: Rule-based plan transformations.</li>
<li><a href="./modules/execution.html"><strong>Execution Engine</strong></a>: The Volcano (iterator) execution model.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quillsql-architecture"><a class="header" href="#quillsql-architecture">QuillSQL Architecture</a></h1>
<p>This document explains how a SQL request flows through QuillSQL, how transactional MVCC and background services plug in, and how the main modules collaborate. All diagrams use Mermaid so you can paste them into any compatible renderer for a richer view.</p>
<hr />
<h2 id="1-end-to-end-request-pipeline"><a class="header" href="#1-end-to-end-request-pipeline">1. End-to-End Request Pipeline</a></h2>
<pre class="mermaid">flowchart TD
    Client[&quot;CLI / HTTP client&quot;] --&gt; API[&quot;bin/client / bin/server&quot;]
    API --&gt; Parser[&quot;sql::parser&quot;]
    Parser --&gt; LPlanner[&quot;plan::LogicalPlanner&quot;]
    LPlanner --&gt; Optimizer[&quot;optimizer::LogicalOptimizer&quot;]
    Optimizer --&gt; PhysPlanner[&quot;plan::PhysicalPlanner&quot;]
    PhysPlanner --&gt; Exec[&quot;execution::ExecutionEngine (Volcano)&quot;]

    subgraph Txn[&quot;Transaction Layer&quot;]
        Session[&quot;session::SessionContext&quot;]
        TM[&quot;transaction::TransactionManager&quot;]
        LM[&quot;transaction::LockManager&quot;]
        Session --&gt; TM --&gt; LM
    end

    Exec --&gt;|Tuple meta &amp; locks| Txn
    Exec --&gt; Storage

    subgraph Storage[&quot;Storage &amp; I/O&quot;]
        TableHeap[&quot;storage::table_heap::TableHeap&quot;]
        Index[&quot;storage::index::B+Tree&quot;]
        Buffer[&quot;buffer::BufferManager&quot;]
        Scheduler[&quot;storage::disk_scheduler (io_uring)&quot;]
        WAL[&quot;recovery::WalManager&quot;]
        TableHeap &lt;--&gt; Buffer
        Index &lt;--&gt; Buffer
        Buffer &lt;--&gt; Scheduler
        WAL --&gt; Scheduler
    end

    Txn --&gt;|WAL payloads| WAL

    Background[&quot;background::workers\n(checkpoint, bg writer, MVCC vacuum)&quot;] --&gt; Buffer
    Background --&gt; WAL
    Background --&gt; TM
</pre>
<p><strong>High-level flow</strong></p>
<ol>
<li>SQL text is parsed into an AST, planned into a <code>LogicalPlan</code>, optimized by a handful of safe rewrite rules, then lowered into a physical operator tree.</li>
<li><code>SessionContext</code> either reuses or creates a transaction and injects isolation/access modes.</li>
<li>Each physical operator is driven by the Volcano pull model (<code>init</code>/<code>next</code>). On entry it obtains a <code>TxnRuntime</code> which supplies a command id plus an MVCC snapshot consistent with the transaction’s isolation level.</li>
<li>Operators consult the snapshot for tuple visibility, acquire table/row locks through <code>TxnRuntime</code>, and issue heap/index operations.</li>
<li>DML operators register undo records and append WAL entries via the transaction manager. When the user commits, the manager emits <code>Commit</code> records, waits for durability as configured, and releases locks.</li>
</ol>
<hr />
<h2 id="2-transaction--mvcc-mechanics"><a class="header" href="#2-transaction--mvcc-mechanics">2. Transaction &amp; MVCC Mechanics</a></h2>
<pre class="mermaid">sequenceDiagram
    participant Session
    participant TM as TransactionManager
    participant Runtime as TxnRuntime
    participant Exec as Operator
    participant Heap as TableHeap

    Session-&gt;&gt;TM: begin(isolation, access_mode)
    TM--&gt;&gt;Session: Transaction handle
    Exec-&gt;&gt;Runtime: TxnRuntime::new(&amp;TM, &amp;mut txn)
    Runtime--&gt;&gt;Exec: {snapshot, command_id}
    loop per tuple
        Exec-&gt;&gt;Heap: next()
        Heap--&gt;&gt;Exec: (rid, meta, tuple)
        Exec-&gt;&gt;Runtime: is_visible(meta)?
        Runtime--&gt;&gt;Exec: yes/no (uses cached snapshot)
        alt Visible
            Exec-&gt;&gt;Runtime: lock_row(...)
            Exec-&gt;&gt;TM: record undo + WAL
        end
    end
    Session-&gt;&gt;TM: commit(txn)
    TM-&gt;&gt;WAL: Transaction(Commit)
    TM-&gt;&gt;TM: wait_for_durable / flush_until
    TM--&gt;&gt;Session: release locks, clear snapshot
</pre>
<ul>
<li>
<p><strong>Snapshots</strong></p>
<ul>
<li><em>Read Committed / Read Uncommitted:</em> Every command refreshes its snapshot and clears any cached value on the transaction handle.</li>
<li><em>Repeatable Read / Serializable:</em> The first command captures a snapshot (<code>xmin</code>, <code>xmax</code>, <code>active_txns</code>) and stores it inside <code>Transaction</code>. Subsequent commands reuse it, ensuring consistent reads.</li>
<li>Background MVCC vacuum consults <code>TransactionManager::oldest_active_txn()</code> to compute <code>safe_xmin</code> and prunes tuple versions whose inserting/deleting transactions precede that boundary.</li>
</ul>
</li>
<li>
<p><strong>Locking</strong><br />
Multi-granularity 2PL (IS/IX/S/SIX/X) enforced by <code>LockManager</code>. Repeatable Read releases shared locks at the end of each command (after verifying visibility). Serializable keeps shared locks through commit. Deadlocks are detected via a wait-for graph; a victim simply fails its lock request.</p>
</li>
<li>
<p><strong>Undo &amp; WAL</strong><br />
<code>Transaction</code> maintains logical undo entries. On abort, the manager emits CLR records and performs the inverse heap operations. Commit waits depend on <code>synchronous_commit</code>. Buffer frames retain their <code>page_lsn</code> so WAL-before-data holds.</p>
</li>
<li>
<p><strong>Executor safeguards</strong><br />
<code>PhysicalUpdate</code> now skips tuple versions created by the same <code>(txn_id, command_id)</code> during the current command. This prevents re-processing the freshly inserted MVCC version and thereby avoids infinite loops.</p>
</li>
</ul>
<hr />
<h2 id="3-storage--buffering"><a class="header" href="#3-storage--buffering">3. Storage &amp; Buffering</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Highlights</th></tr></thead><tbody>
<tr><td><code>TableHeap</code></td><td>Tuple metadata (<code>TupleMeta</code>) stores inserting/deleting txn ids, command ids, and forward/back pointers for version chains. Helpers like <code>mvcc_update</code> stitch new versions while marking old ones deleted.</td></tr>
<tr><td><code>B+Tree</code></td><td>B-link tree implementation with separate codecs for header/internal/leaf pages. Index maintenance occurs in DML operators after the heap change succeeds.</td></tr>
<tr><td><code>BufferManager</code></td><td>Combines a page table, LRU-K replacer (with TinyLFU admission option), and per-frame guards. Dirty pages record their first-dirty LSN, feeding checkpoints. The background writer periodically flushes dirty frames and drives lazy index cleanup.</td></tr>
<tr><td><code>DiskScheduler</code></td><td>Uses io_uring worker threads. Foreground tasks push <code>ReadPage</code>, <code>WritePage</code>, <code>WriteWal</code>, and <code>FsyncWal</code> commands through lock-free queues and receive completion on dedicated channels.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="4-write-ahead-logging--recovery"><a class="header" href="#4-write-ahead-logging--recovery">4. Write-Ahead Logging &amp; Recovery</a></h2>
<ul>
<li><code>WalManager</code> manages log sequence numbers, buffers frames, writes physical (<code>PageWrite</code>, <code>PageDelta</code>) and logical (<code>HeapInsert/Update/Delete</code>) records, and coordinates flushes. First-page-writes guard against torn pages.</li>
<li><code>background::spawn_checkpoint_worker</code> emits <code>Checkpoint</code> records capturing the dirty page table and active transactions so recovery can cut replay short.</li>
<li><code>RecoveryManager</code> executes ARIES-style <strong>analysis → redo → undo</strong> on restart, leveraging CLRs to keep undo idempotent.</li>
<li>WAL and data I/O both use the <code>DiskScheduler</code>, keeping durability guarantees in one place.</li>
</ul>
<hr />
<h2 id="5-background-services"><a class="header" href="#5-background-services">5. Background Services</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Worker</th><th>Description</th><th>Trigger</th></tr></thead><tbody>
<tr><td>WAL writer</td><td>Coalesces buffered WAL into durable segments</td><td><code>WalManager::start_background_flush</code></td></tr>
<tr><td>Checkpoint</td><td>Flushes LSNs, records ATT + DPT snapshots, resets FPW epoch</td><td>Configurable interval (<code>WalOptions::checkpoint_interval_ms</code>)</td></tr>
<tr><td>Buffer writer</td><td>Flushes dirty frames, runs index lazy cleanup based on pending garbage counters</td><td><code>IndexVacuumConfig</code></td></tr>
<tr><td>MVCC vacuum</td><td>Iterates table heaps, removing committed-deleted or aborted-inserted tuples older than <code>safe_xmin</code></td><td><code>MvccVacuumConfig</code> (interval + batch limit)</td></tr>
</tbody></table>
</div>
<p>All workers are registered with <code>background::BackgroundWorkers</code>, which stops and joins them on database shutdown.</p>
<hr />
<h2 id="6-example-timeline-repeatable-read-update"><a class="header" href="#6-example-timeline-repeatable-read-update">6. Example Timeline: Repeatable Read UPDATE</a></h2>
<pre><code>T1 (RR)                               T2 (RC)
-----------                           -----------
BEGIN;                                BEGIN;
SELECT ... (snapshot S0)              UPDATE row -&gt; new version V1
                                      COMMIT (WAL + flush)
SELECT again -&gt; sees original value
COMMIT
-- background vacuum later reclaims deleted version when safe_xmin &gt; delete_txn
</code></pre>
<ul>
<li>T1’s <code>TxnRuntime</code> caches snapshot S0 on its first command and reuses it, so the second <code>SELECT</code> filters out V1 even though T2 committed.</li>
<li>Row-level shared locks acquired during the read are released at the end of the command, while the MVCC snapshot keeps the view consistent.</li>
<li>When T1 commits, locks are dropped, snapshot cache is cleared, and WAL commit record becomes durable. Vacuum eventually removes T1’s deleted predecessor when all transactions with <code>txn_id &lt; safe_xmin</code> have finished.</li>
</ul>
<hr />
<h2 id="7-observability--configuration"><a class="header" href="#7-observability--configuration">7. Observability &amp; Configuration</a></h2>
<ul>
<li>Enable tracing via <code>RUST_LOG=trace</code> to inspect lock grant/queue events and MVCC vacuum activity.</li>
<li>Key knobs exposed through CLI/environment: WAL segment size, background intervals, default isolation level, MVCC vacuum batch size.</li>
<li><code>background::BackgroundWorkers::snapshot()</code> reports active worker metadata; you can surface it for debugging endpoints.</li>
</ul>
<hr />
<h2 id="8-roadmap"><a class="header" href="#8-roadmap">8. Roadmap</a></h2>
<ul>
<li>Predicate locking / SSI to upgrade Serializable beyond strict 2PL.</li>
<li>Cost-based optimization with catalog statistics.</li>
<li>Smarter vacuum pacing tied to storage pressure and tuple churn.</li>
<li>Parallel execution and adaptive readahead hints based on operator feedback.</li>
</ul>
<p>Even with these future items, the current layering mirrors production databases (e.g., PostgreSQL): MVCC + 2PL, ARIES-style WAL, asynchronous maintenance, and a modular Volcano executor—all while keeping the codebase approachable for teaching and experimentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="module-overview"><a class="header" href="#module-overview">Module Overview</a></h1>
<p>This page gives a teaching-friendly tour of every QuillSQL subsystem. Each section
explains where the code lives (<code>src/&lt;module&gt;</code>), the most important types, and the
design decisions that make the module fit into the whole system. Read it together
with <a href="modules/../architecture.html"><code>architecture.md</code></a> for the big-picture data flow.</p>
<hr />
<h2 id="1-sql-front-end-srcsql"><a class="header" href="#1-sql-front-end-srcsql">1. SQL Front-End (<code>src/sql</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Submodule</th><th>Responsibilities</th><th>Key Types / Functions</th></tr></thead><tbody>
<tr><td><code>lexer.rs</code>, <code>parser.rs</code></td><td>Translate raw SQL into an AST using <code>sqlparser</code> plus Quill-specific extensions.</td><td><code>parse_sql(&amp;str) -&gt; Vec&lt;Statement&gt;</code></td></tr>
<tr><td><code>ast/mod.rs</code></td><td>Normalises identifiers, handles multi-part names, attaches spans for diagnostics.</td><td><code>NormalizedIdent</code>, <code>ObjectNameExt</code></td></tr>
<tr><td><code>plan/lowering.rs</code></td><td>Bridges AST → planner structs for DDL extras not in upstream <code>sqlparser</code>.</td><td><code>CreateIndexSpec</code>, <code>ColumnDefExt</code></td></tr>
</tbody></table>
</div>
<p>Implementation notes:</p>
<ul>
<li>We intentionally keep the AST “SQL-shaped”. No premature desugaring occurs in the
parser, which keeps the step-by-step teaching narrative simple: <strong>SQL text → AST →
logical plan</strong>.</li>
<li>Error messages bubble up with span information, so labs around parser extensions can
show students exactly which token misbehaved.</li>
<li>Suggested exercises: extend the parser with <code>ALTER TABLE</code> or window functions, then
observe how the new AST nodes flow into the planner layer.</li>
</ul>
<hr />
<h2 id="2-logical-planning-srcplan"><a class="header" href="#2-logical-planning-srcplan">2. Logical Planning (<code>src/plan</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody>
<tr><td><code>LogicalPlanner</code></td><td>Converts AST nodes into strongly typed <code>LogicalPlan</code> variants. Responsible for type checking, alias resolution, and scope handling.</td></tr>
<tr><td><code>PlannerContext</code></td><td>Surface for catalog lookups while planning.</td></tr>
<tr><td><code>PhysicalPlanner</code></td><td>Lowers optimized logical plans into physical Volcano operators (<code>PhysicalPlan</code>).</td></tr>
</tbody></table>
</div>
<p>Highlights:</p>
<ul>
<li>Every <code>LogicalPlan</code> variant stores its child plans in <code>Arc</code>, so the tree is cheap to
clone for optimizer passes or debugging prints.</li>
<li>Planner enforces column binding rules: scope stacks keep track of aliases, CTEs, and
correlation so students can see how real compilers resolve identifiers.</li>
<li>DDL nodes capture <code>TableReference</code> + <code>Schema</code> objects. Later phases use them to skip
repeated catalog lookups (helpful for labs about metadata caching).</li>
</ul>
<hr />
<h2 id="3-optimizer-srcoptimizer"><a class="header" href="#3-optimizer-srcoptimizer">3. Optimizer (<code>src/optimizer</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Piece</th><th>Responsibility</th></tr></thead><tbody>
<tr><td><code>LogicalOptimizer</code></td><td>Applies a pipeline of rule-based rewrites (predicate pushdown, projection pruning, constant folding).</td></tr>
<tr><td><code>rules</code></td><td>Individual <code>OptimizerRule</code> implementations.</td></tr>
</tbody></table>
</div>
<p>Teaching hooks:</p>
<ul>
<li>Each rule implements <code>OptimizerRule::rewrite(&amp;LogicalPlan) -&gt; Option&lt;LogicalPlan&gt;</code>. The
return type makes it obvious whether a rewrite fired, so labs can instrument hit counts
or add tracing.</li>
<li>Because rules are pure functions, students can safely reorder or A/B test heuristics in
isolation (e.g., “what if we only push predicates below joins when the selectivity
estimate exceeds X?”).</li>
<li>Example lab: add constant folding or join commutation, run the sqllogictest suite, and
compare plan dumps to see new shapes.</li>
</ul>
<hr />
<h2 id="4-execution-engine-srcexecution"><a class="header" href="#4-execution-engine-srcexecution">4. Execution Engine (<code>src/execution</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Element</th><th>Details</th></tr></thead><tbody>
<tr><td><code>PhysicalPlan</code></td><td>Enum covering all Volcano operators. Each variant implements <code>VolcanoExecutor</code>.</td></tr>
<tr><td><code>VolcanoExecutor</code></td><td><code>init(&amp;mut ExecutionContext)</code> and <code>next(&amp;mut ExecutionContext)</code> pair define the iterator model.</td></tr>
<tr><td><code>ExecutionContext</code></td><td>Supplies catalog access, expression evaluation, and (most importantly) a pluggable <code>StorageEngine</code>.</td></tr>
</tbody></table>
</div>
<p>Design notes:</p>
<ul>
<li>Operators stay declarative. They describe <em>what</em> to scan or modify and delegate the
<em>how</em> to storage handles. For example, <code>PhysicalSeqScan</code> now requests a <code>TupleStream</code>
via <code>ExecutionContext::table_stream</code>, so it never touches <code>TableHeap</code> internals.</li>
<li>Helper methods such as <code>eval_predicate</code>, <code>insert_tuple_with_indexes</code>, or
<code>prepare_row_for_write</code> encapsulate MVCC/locking rules so physical plans remain short.</li>
<li>ExecutionContext caches <code>TxnContext</code>, making it straightforward to teach isolation
semantics: examine <code>TxnContext::lock_table</code> and <code>read_visible_tuple</code> to see when locks
are taken or released.</li>
<li>Suggested lab: implement a new physical operator (e.g., hash join) by wiring two child
<code>PhysicalPlan</code>s without ever touching storage-specific code. This highlights the payoff
of the handle abstraction.</li>
</ul>
<hr />
<h2 id="5-transaction-runtime-srctransaction"><a class="header" href="#5-transaction-runtime-srctransaction">5. Transaction Runtime (<code>src/transaction</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>TransactionManager</code></td><td>Creates/commits/aborts transactions, manages undo chains, and coordinates WAL durability.</td></tr>
<tr><td><code>TxnContext</code></td><td>Per-command wrapper passed to execution. Provides MVCC snapshot (<code>TransactionSnapshot</code>), lock helpers, and command ids.</td></tr>
<tr><td><code>LockManager</code></td><td>Multi-granularity 2PL with deadlock detection.</td></tr>
</tbody></table>
</div>
<p>Deeper dive:</p>
<ul>
<li><code>Transaction</code> stores a cached <code>TransactionSnapshot</code> plus its undo records. Students can
inspect <code>Transaction::set_snapshot</code> to see how Repeatable Read/Serializable keep a
stable view.</li>
<li><code>TxnRuntime</code> pairs a transaction with a command id. Every SQL statement increments the
command id so MVCC can distinguish between tuples created earlier in the same
transaction vs. the current statement—great for explaining “recent writes are invisible
during UPDATE scanning”.</li>
<li><code>LockManager</code> exposes functions like <code>lock_table</code> / <code>lock_row</code>. Internally it keeps a
wait-for graph and victim selection policy, which makes deadlock detection tangible for
concurrency lectures.</li>
<li>Undo entries (<code>UndoRecord</code>) store heap + index data. When an abort occurs the engine
generates CLRs, demonstrating ARIES-style logical undo.</li>
</ul>
<hr />
<h2 id="6-storage-engine--handles-srcstorage"><a class="header" href="#6-storage-engine--handles-srcstorage">6. Storage Engine &amp; Handles (<code>src/storage</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Highlights</th></tr></thead><tbody>
<tr><td><code>engine.rs</code></td><td>Defines <code>StorageEngine</code>, <code>TableHandle</code>, <code>IndexHandle</code>, <code>TupleStream</code>, and the new <code>ScanOptions</code> / <code>IndexScanRequest</code>.</td></tr>
<tr><td><code>table_heap</code></td><td>Slotted-page heap with MVCC metadata (<code>TupleMeta</code>, forward/back pointers).</td></tr>
<tr><td><code>index</code></td><td>B+Tree (B-link) implementation with iterators and codecs.</td></tr>
</tbody></table>
</div>
<p>Key ideas for teaching:
Topics to emphasise:</p>
<ul>
<li><strong>Handle abstraction</strong>: Execution asks the engine for a <code>TableHandle</code>, then calls
<code>full_scan(ScanOptions)</code> to receive a <code>TupleStream</code>. The default engine simply wraps
<code>TableHeap</code>/<code>BPlusTreeIndex</code>, but students can plug in their own engines for research.</li>
<li><strong>TupleStream</strong>: Minimal interface returning <code>(RecordId, TupleMeta, Tuple)</code> triples.
Operators layer MVCC visibility on top, while the stream hides buffering details.</li>
<li><strong>ScanOptions</strong>: Carry streaming hints, projection slots, or batch sizes. Even when the
default heap ignores some hints, the API teaches how modern engines negotiate capabilities.</li>
<li><code>table_heap</code> demonstrates MVCC version chains (forward/back pointers) and the slotted
page layout. Encourage students to trace <code>MvccHeap::update</code> alongside WAL entries to
see how new versions link together.</li>
<li><code>index/btree_index.rs</code> implements a B-link tree with separate codecs. Scanning via
<code>TreeIndexIterator</code> shows how to perform lock-free range scans using sibling pointers—
perfect for advanced systems lectures.</li>
</ul>
<hr />
<h2 id="7-buffer-manager--disk-io-srcbuffer-srcstoragedisk_"><a class="header" href="#7-buffer-manager--disk-io-srcbuffer-srcstoragedisk_">7. Buffer Manager &amp; Disk I/O (<code>src/buffer</code>, <code>src/storage/disk_*</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>buffer::BufferManager</code></td><td>Page table + LRU-K/TinyLFU replacer, dirty tracking, guard types for safe borrowing.</td></tr>
<tr><td><code>storage::disk_scheduler</code></td><td><code>io_uring</code>-powered async I/O. Foreground threads enqueue read/write/fsync commands and await completions.</td></tr>
<tr><td><code>storage::disk_manager</code></td><td>Thin wrapper for file layout, page enlargement, and durability fences.</td></tr>
</tbody></table>
</div>
<p>Extra details:</p>
<ul>
<li>Page guards come in three flavours: read, write, and upgradeable. Each implements <code>Drop</code>
semantics that release latches automatically, reinforcing RAII patterns.</li>
<li>Replacement policy combines LRU-K history with TinyLFU admission. Labs can toggle the
feature flag to measure hit-rate differences under sqllogictest or custom workloads.</li>
<li>DiskScheduler uses lock-free queues plus dedicated worker tasks. A teaching exercise is
to run with <code>RUST_LOG=debug</code> and observe how read/write/fsync commands are batched.</li>
</ul>
<hr />
<h2 id="8-recovery--wal-srcrecovery"><a class="header" href="#8-recovery--wal-srcrecovery">8. Recovery &amp; WAL (<code>src/recovery</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Item</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>WalManager</code></td><td>Allocates LSNs, buffers log records, drives background WAL writer, and integrates with checkpoints.</td></tr>
<tr><td><code>RecoveryManager</code></td><td>Implements ARIES analysis/redo/undo. Uses <code>ControlFileManager</code> snapshots to seed restart.</td></tr>
<tr><td><code>wal_record.rs</code></td><td>Defines logical (<code>HeapInsert</code>, <code>IndexDelete</code>) and physical (<code>PageWrite</code>, <code>PageDelta</code>) records.</td></tr>
</tbody></table>
</div>
<p>Teaching hook:</p>
<ul>
<li>WAL and data share the disk scheduler. Students can trace one UPDATE from log append,
to buffer dirtying, to redo/undo via the exact same <code>RecordId</code>.</li>
<li>Recovery exports statistics (redo count, loser transactions) so labs can check their
WAL experiments automatically.</li>
<li><code>recovery/analysis.rs</code> shows how Dirty Page Table and Active Transaction Table are
reconstructed—ideal for demystifying ARIES’ first phase.</li>
<li>Students can implement “logical replay only” or “page image replay” modes by toggling
the commit record types, then verify behaviour using the provided transaction tests.</li>
</ul>
<hr />
<h2 id="9-background-services-srcbackground"><a class="header" href="#9-background-services-srcbackground">9. Background Services (<code>src/background</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Worker</th><th>What it does</th></tr></thead><tbody>
<tr><td>WAL writer</td><td>Flushes WAL buffer at configured cadence.</td></tr>
<tr><td>Checkpoint</td><td>Captures the Dirty Page Table + Active Transaction Table.</td></tr>
<tr><td>Buffer writer</td><td>Flushes dirty frames and kicks lazy index cleanup.</td></tr>
<tr><td>MVCC vacuum</td><td>Reclaims tuple versions older than <code>safe_xmin</code>.</td></tr>
</tbody></table>
</div>
<p>More context:</p>
<ul>
<li>Workers share a <code>BackgroundWorkers</code> registry so the database can spawn/stop them as a
group (handy for tests). The registry exposes <code>shutdown_all()</code> which unit tests call to
ensure a clean exit.</li>
<li>Config structs (<code>IndexVacuumConfig</code>, <code>MvccVacuumConfig</code>, etc.) live in <code>src/config</code>
and are exposed through <code>DatabaseOptions</code> for easy fiddling in labs.</li>
<li>WAL writer and checkpoint worker simply wrap closures around <code>tokio::task::JoinHandle</code>.
This design keeps async runtime code out of the core engine, making it simpler for
students to trace background effects.</li>
<li>Exercise idea: tweak <code>MvccVacuumConfig::batch_limit</code> and observe how many tuple
versions stay behind by querying hidden statistics tables.</li>
</ul>
<hr />
<h2 id="10-configuration--session-layer-srcdatabase-srcsession-srcconfig"><a class="header" href="#10-configuration--session-layer-srcdatabase-srcsession-srcconfig">10. Configuration &amp; Session Layer (<code>src/database</code>, <code>src/session</code>, <code>src/config</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Role</th></tr></thead><tbody>
<tr><td><code>Database</code></td><td>Boots disk/WAL/buffer components, runs recovery, wires background workers, and executes SQL strings.</td></tr>
<tr><td><code>SessionContext</code></td><td>Tracks per-connection defaults (autocommit, isolation) and holds the active transaction handle.</td></tr>
<tr><td><code>config::*</code></td><td>Central place for WAL, buffer pool, vacuum, and HTTP/CLI tuning knobs.</td></tr>
</tbody></table>
</div>
<p>Extra pointers:</p>
<ul>
<li>Front-ends (<code>bin/client</code>, <code>bin/server</code>) both embed a <code>Database</code>, proving that the core
library can serve multiple UIs without change.</li>
<li><code>DatabaseOptions</code> show how to construct dev/test setups (temporary files, alternate WAL
directories) in a few lines.</li>
<li><code>session::SessionContext</code> demonstrates auto-commit semantics: it lazily starts a
transaction and uses <code>TransactionScope</code> to interpret <code>SET TRANSACTION</code> statements.</li>
<li>Configuration structs derive <code>Clone + Debug</code>, making them easy to print in labs or
feed from environment variables (HTTP server uses <code>QUILL_DB_FILE</code>, <code>PORT</code>, etc.).</li>
</ul>
<hr />
<h2 id="11-testing--documentation-tests-docs"><a class="header" href="#11-testing--documentation-tests-docs">11. Testing &amp; Documentation (<code>tests/</code>, <code>docs/</code>)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Area</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tests/sql_example/*.slt</code></td><td>sqllogictest suites for SQL coverage.</td></tr>
<tr><td><code>tests/transaction_tests.rs</code></td><td>Unit tests for MVCC invariants, locking, and visibility.</td></tr>
<tr><td><code>docs/</code></td><td>This mdBook. Every module adds its own deep-dive chapter, making it straightforward for students to jump from code to guided explanations.</td></tr>
</tbody></table>
</div>
<p>Testing strategy:</p>
<ul>
<li>Developers can run <code>cargo test -q</code> for fast feedback. Long-running suites can be wrapped
with <code>timeout</code> as suggested in <code>AGENTS.md</code>.</li>
<li>Example-driven docs (like this page) mirror the repository layout, so onboarding students
can find code and tests with minimal guesswork.</li>
<li>Encourage students to add sqllogictest cases alongside code changes. Because each case lives
in <code>tests/sql_example</code>, git diffs double as documentation.</li>
<li>For modules with heavy concurrency (lock manager, WAL), pair unit tests with tracing: the
CI logs become walkthroughs for tricky paths.</li>
</ul>
<hr />
<h2 id="12-suggested-reading-order-for-learners"><a class="header" href="#12-suggested-reading-order-for-learners">12. Suggested Reading Order for Learners</a></h2>
<ol>
<li><strong>Introduction ➜ Architecture</strong> – get the 10,000ft view.</li>
<li><strong>Module Overview (this page)</strong> – map names to directories.</li>
<li><strong>Execution + Storage chapters</strong> – understand TupleStreams, handles, and MVCC.</li>
<li><strong>Recovery + Transaction</strong> – see how WAL &amp;&amp; MVCC interlock.</li>
<li><strong>Buffer, Index, Background</strong> – dive into advanced systems topics once the basics stick.</li>
</ol>
<p>Treat this document as a living index: update it whenever a subsystem gains new entry
points (e.g., asynchronous scans, new index types) so future contributors always know
where to look next.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributors-guide"><a class="header" href="#contributors-guide">Contributor's Guide</a></h1>
<p>Welcome, and thank you for your interest in contributing to QuillSQL! Whether you're fixing a bug, adding a new feature, or improving the documentation, this guide will help you get started.</p>
<h2 id="1-getting-started-your-development-environment"><a class="header" href="#1-getting-started-your-development-environment">1. Getting Started: Your Development Environment</a></h2>
<h3 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h3>
<ul>
<li><strong>Rust</strong>: QuillSQL is written in Rust. If you don't have it yet, install it via <a href="https://rustup.rs/">rustup</a>. This will provide you with <code>rustc</code> (the compiler) and <code>cargo</code> (the package manager and build tool).
<pre><code class="language-bash">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
</code></pre>
</li>
<li><strong>Build Essentials</strong>: Ensure you have a C++ compiler like <code>gcc</code> or <code>clang</code> installed, which is a common dependency for some Rust crates.</li>
</ul>
<h3 id="setup"><a class="header" href="#setup">Setup</a></h3>
<ol>
<li>
<p><strong>Fork the Repository</strong>: Start by forking the main QuillSQL repository to your own GitHub account.</p>
</li>
<li>
<p><strong>Clone Your Fork</strong>: Clone your forked repository to your local machine.</p>
<pre><code class="language-bash">git clone https://github.com/feichai0017/QuillSQL.git
cd QuillSQL
</code></pre>
</li>
<li>
<p><strong>Build the Project</strong>: Compile the entire project to ensure everything is set up correctly.</p>
<pre><code class="language-bash">cargo build
</code></pre>
</li>
</ol>
<h2 id="2-development-workflow"><a class="header" href="#2-development-workflow">2. Development Workflow</a></h2>
<h3 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h3>
<p>Before and after making any changes, it's crucial to run the test suite to ensure you haven't broken anything.</p>
<ul>
<li>
<p><strong>Run all unit and integration tests</strong>:</p>
<pre><code class="language-bash">cargo test
</code></pre>
</li>
<li>
<p><strong>Run the benchmark suite</strong>:</p>
<pre><code class="language-bash">cargo bench
</code></pre>
</li>
</ul>
<h3 id="code-style-and-quality"><a class="header" href="#code-style-and-quality">Code Style and Quality</a></h3>
<p>We adhere to the standard Rust coding style and use tools to enforce it.</p>
<ul>
<li>
<p><strong>Formatting</strong>: Before committing, please format your code with <code>rustfmt</code>.</p>
<pre><code class="language-bash">cargo fmt --all
</code></pre>
</li>
<li>
<p><strong>Linting</strong>: We use <code>clippy</code> to catch common mistakes and improve code quality. Please ensure <code>clippy</code> passes without warnings.</p>
<pre><code class="language-bash">cargo clippy --all-targets -- -D warnings
</code></pre>
</li>
</ul>
<h3 id="submitting-your-contribution"><a class="header" href="#submitting-your-contribution">Submitting Your Contribution</a></h3>
<ol>
<li>
<p><strong>Create a New Branch</strong>: Create a descriptive branch name for your feature or bugfix.</p>
<pre><code class="language-bash">git checkout -b my-awesome-feature
</code></pre>
</li>
<li>
<p><strong>Make Your Changes</strong>: Write your code. Add new tests to cover your changes. Ensure all existing tests still pass.</p>
</li>
<li>
<p><strong>Format and Lint</strong>: Run <code>cargo fmt</code> and <code>cargo clippy</code> as described above.</p>
</li>
<li>
<p><strong>Commit Your Work</strong>: Write a clear and concise commit message.</p>
<pre><code class="language-bash">git add .
git commit -m "feat: Add support for window functions"
</code></pre>
</li>
<li>
<p><strong>Push to Your Fork</strong>: Push your branch to your fork on GitHub.</p>
<pre><code class="language-bash">git push -u origin my-awesome-feature
</code></pre>
</li>
<li>
<p><strong>Open a Pull Request</strong>: Go to the original QuillSQL repository on GitHub. You should see a prompt to open a Pull Request from your new branch. Fill out the PR template with a description of your changes.</p>
</li>
</ol>
<h2 id="3-working-on-the-documentation"><a class="header" href="#3-working-on-the-documentation">3. Working on the Documentation</a></h2>
<p>The documentation is built using <code>mdbook</code>. To preview your changes locally, you'll need to install it and the <code>mermaid</code> plugin.</p>
<ol>
<li>
<p><strong>Install <code>mdbook</code> and <code>mdbook-mermaid</code></strong>:</p>
<pre><code class="language-bash">cargo install mdbook
cargo install mdbook-mermaid
</code></pre>
</li>
<li>
<p><strong>Serve the Book Locally</strong>: Run the following command from the root of the project.</p>
<pre><code class="language-bash">mdbook serve docs
</code></pre>
<p>This will build the book and start a local web server. You can open your browser to <code>http://localhost:3000</code> to see the live-previewed documentation.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sql-front-end"><a class="header" href="#sql-front-end">SQL Front-End</a></h1>
<p>The SQL front-end lives in <code>src/sql/</code>. It turns raw UTF-8 query text into the abstract
syntax trees (ASTs) consumed by planning, while layering Quill-specific name handling
and diagnostics on top of <a href="https://docs.rs/sqlparser"><code>sqlparser</code></a>.</p>
<hr />
<h2 id="responsibilities"><a class="header" href="#responsibilities">Responsibilities</a></h2>
<ul>
<li>Parse SQL text into <code>sqlparser::ast::Statement</code> values.</li>
<li>Record precise spans so error messages can highlight the exact byte range.</li>
<li>Normalise identifiers (case folding, quoted names, multi-part paths).</li>
<li>Provide helper traits so the logical planner can lower AST nodes without duplicating
syntax checks.</li>
</ul>
<hr />
<h2 id="directory-layout"><a class="header" href="#directory-layout">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Purpose</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>lexer.rs</code></td><td>Token helpers that preserve offsets.</td><td><code>Token</code>, <code>TokenExt</code></td></tr>
<tr><td><code>parser.rs</code></td><td>Single entry point used across the codebase.</td><td><code>parse_sql</code>, <code>SqlInput</code></td></tr>
<tr><td><code>ast/mod.rs</code></td><td>Planner-facing helpers.</td><td><code>NormalizedIdent</code>, <code>ObjectNameExt</code></td></tr>
<tr><td><code>error.rs</code></td><td>Span-aware parser errors.</td><td><code>SqlError</code>, <code>SqlSpan</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="parsing-pipeline"><a class="header" href="#parsing-pipeline">Parsing Pipeline</a></h2>
<ol>
<li><strong>Lexing</strong> – wrap sqlparser’s lexer so every token keeps start/end offsets.</li>
<li><strong>AST generation</strong> – invoke sqlparser to produce standard <code>Statement</code> structs.</li>
<li><strong>Normalisation</strong> – convert identifiers into <code>NormalizedIdent</code>, deal with schema
qualifiers, and build pieces of <code>TableReference</code>.</li>
<li><strong>Planner bridge</strong> – traits like <code>ColumnRefExt</code> expose methods such as <code>relation()</code> or
<code>column()</code> so <code>LogicalPlanner</code> can treat different SQL syntaxes uniformly.</li>
</ol>
<hr />
<h2 id="interactions"><a class="header" href="#interactions">Interactions</a></h2>
<ul>
<li><strong>Logical planner</strong> consumes the AST directly and relies on helper traits from this
module to convert identifiers into catalog references.</li>
<li><strong>Database / Session</strong> catch <code>SqlError</code> values, so both CLI and HTTP front-ends show
consistent caret diagnostics.</li>
<li><strong>Tests</strong> (<code>tests/sql_example/*.slt</code>, <code>tests/sql_parser.rs</code>) assert on parser output and
error strings to keep teaching feedback stable.</li>
</ul>
<hr />
<h2 id="implementation-notes"><a class="header" href="#implementation-notes">Implementation Notes</a></h2>
<ul>
<li><code>SqlSpan</code> stores byte offsets, which makes it trivial to slice the original SQL and
render highlighted errors.</li>
<li>Extended statements (e.g., <code>EXPLAIN</code>, <code>BEGIN TRANSACTION</code>) show how to Layer
Quill-specific syntax without forking sqlparser entirely.</li>
<li>We avoid desugaring at this stage so students can trace SQL → AST → logical plan step
by step.</li>
</ul>
<hr />
<h2 id="teaching-ideas"><a class="header" href="#teaching-ideas">Teaching Ideas</a></h2>
<ul>
<li>Add a new statement (<code>CREATE VIEW</code>, <code>ALTER TABLE ...</code>) and follow the AST through the
pipeline.</li>
<li>Improve error hints (“Did you forget FROM?”) to see how better diagnostics aid users.</li>
<li>Write fuzz tests that round-trip SQL → AST → SQL to discuss parser determinism.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="catalog-module"><a class="header" href="#catalog-module">Catalog Module</a></h1>
<p><code>src/catalog/</code> acts as QuillSQL’s data dictionary. It tracks schema/table/index metadata,
statistics, and the mapping between logical names and physical storage objects such as
<code>TableHeap</code> and <code>BPlusTreeIndex</code>. Every layer—planner, execution, background workers—uses
the catalog to discover structure.</p>
<hr />
<h2 id="responsibilities-1"><a class="header" href="#responsibilities-1">Responsibilities</a></h2>
<ul>
<li>Persist definitions for schemas, tables, columns, indexes, and constraints.</li>
<li>Map logical <code>TableReference</code>s to physical handles (heap files, index roots, file ids).</li>
<li>Store table statistics (row counts, histograms) that drive ANALYZE and optimization.</li>
<li>Manage the DDL lifecycle: creation and deletion update the in-memory registry and the
on-disk metadata pages.</li>
</ul>
<hr />
<h2 id="directory-layout-1"><a class="header" href="#directory-layout-1">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>mod.rs</code></td><td>Public API surface.</td><td><code>Catalog</code>, <code>TableHandleRef</code></td></tr>
<tr><td><code>schema.rs</code></td><td>Schema objects and table references.</td><td><code>Schema</code>, <code>Column</code>, <code>TableReference</code></td></tr>
<tr><td><code>registry/</code></td><td>Thread-safe registries for heaps and indexes.</td><td><code>TableRegistry</code>, <code>IndexRegistry</code></td></tr>
<tr><td><code>statistics.rs</code></td><td>ANALYZE output and helpers.</td><td><code>TableStatistics</code></td></tr>
<tr><td><code>loader.rs</code></td><td>Boot-time metadata loader.</td><td><code>load_catalog_data</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="tablereference"><a class="header" href="#tablereference">TableReference</a></h3>
<p>Unified identifier (database, schema, table). Logical planner, execution, and transaction
code all use it when requesting handles from the catalog.</p>
<h3 id="registries"><a class="header" href="#registries">Registries</a></h3>
<p><code>TableRegistry</code>/<code>IndexRegistry</code> map internal IDs to <code>Arc&lt;TableHeap&gt;</code> or
<code>Arc&lt;BPlusTreeIndex&gt;</code> plus logical names. They are thread-safe so background tasks can
traverse them without blocking the main thread.</p>
<h3 id="schema--column"><a class="header" href="#schema--column">Schema &amp; Column</a></h3>
<p><code>Schema</code> stores column definitions (type, default, nullability). Execution uses it when
materialising tuples; the planner uses it to check expression types. <code>Schema::project</code>
helps physical operators build projected outputs.</p>
<h3 id="tablestatistics"><a class="header" href="#tablestatistics">TableStatistics</a></h3>
<p><code>ANALYZE</code> writes row counts and histograms into the catalog. Optimizer rules and planner
heuristics can consult these stats when deciding whether to push filters or pick indexes.</p>
<hr />
<h2 id="interactions-1"><a class="header" href="#interactions-1">Interactions</a></h2>
<ul>
<li><strong>SQL / Planner</strong> – DDL planning calls <code>Catalog::create_table</code> / <code>create_index</code>; name
binding relies on <code>Schema</code>.</li>
<li><strong>Execution</strong> – <code>ExecutionContext::table_handle</code> and <code>index_handle</code> fetch physical
handles through the catalog, so scans never hard-code heap locations.</li>
<li><strong>Background workers</strong> – MVCC and index vacuum iterate the registries via <code>Arc</code> clones.</li>
<li><strong>Recovery</strong> – <code>load_catalog_data</code> rebuilds the in-memory catalog from control files and
metadata pages during startup.</li>
</ul>
<hr />
<h2 id="teaching-ideas-1"><a class="header" href="#teaching-ideas-1">Teaching Ideas</a></h2>
<ul>
<li>Extend the schema system with hidden or computed columns and teach the catalog to store
the extra metadata.</li>
<li>Add histogram bins to <code>TableStatistics</code> and demonstrate how a simple cost heuristic can
choose better plans.</li>
<li>Turn on <code>RUST_LOG=catalog=debug</code> to observe how DDL mutates the registries.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="expression--scalar-evaluation"><a class="header" href="#expression--scalar-evaluation">Expression &amp; Scalar Evaluation</a></h1>
<p>The expression subsystem (<code>src/expression/</code>) powers column computations, predicates, and
UPDATE assignments. It keeps expression trees approachable while demonstrating how they
are evaluated during execution.</p>
<hr />
<h2 id="responsibilities-2"><a class="header" href="#responsibilities-2">Responsibilities</a></h2>
<ul>
<li>Store planner-produced expression trees (<code>Expr</code>) in a serializable, traversable enum.</li>
<li>Bind column references, constants, and built-in functions.</li>
<li>Evaluate expressions against <code>Tuple</code>s at runtime, yielding <code>ScalarValue</code>.</li>
<li>Provide type inference and casting so arithmetic/comparison operators remain well-typed.</li>
</ul>
<hr />
<h2 id="directory-layout-2"><a class="header" href="#directory-layout-2">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>mod.rs</code></td><td>Public API and core enum.</td><td><code>Expr</code>, <code>ExprTrait</code></td></tr>
<tr><td><code>scalar.rs</code></td><td>Runtime scalar representation + conversions.</td><td><code>ScalarValue</code>, <code>DataType</code></td></tr>
<tr><td><code>binder.rs</code></td><td>Helpers for the planner/SQL binder.</td><td><code>BoundExpr</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="concepts"><a class="header" href="#concepts">Concepts</a></h2>
<h3 id="expr-enum"><a class="header" href="#expr-enum">Expr Enum</a></h3>
<p>Expresses column refs, literals, comparisons, logical ops, arithmetic, and function
invocations. Each variant implements <code>ExprTrait::evaluate(&amp;self, tuple)</code> and returns a
<code>ScalarValue</code>.</p>
<h3 id="scalarvalue"><a class="header" href="#scalarvalue">ScalarValue</a></h3>
<p>Unified runtime value across types (int, bigint, bool, decimal, varchar, …). Includes
<code>cast_to(DataType)</code> so results can be coerced to the target column type before writes.</p>
<h3 id="type-inference"><a class="header" href="#type-inference">Type Inference</a></h3>
<p>Planner code invokes <code>Expr::data_type(schema)</code> to predict result types. Execution then
casts when needed—e.g., <code>UPDATE t SET a = b + 1</code> uses the column’s declared type for <code>a</code>.</p>
<hr />
<h2 id="interactions-2"><a class="header" href="#interactions-2">Interactions</a></h2>
<ul>
<li><strong>Planner</strong> – builds <code>Expr</code> trees with bound columns; execution reuses them verbatim.</li>
<li><strong>ExecutionContext</strong> – exposes <code>eval_expr</code> and <code>eval_predicate</code>, wrapping expression
evaluation plus boolean coercion (<code>NULL</code> becomes false for predicates).</li>
<li><strong>Optimizer</strong> – rules like constant folding traverse <code>Expr</code> trees and reuse
<code>ScalarValue</code> arithmetic helpers.</li>
</ul>
<hr />
<h2 id="teaching-ideas-2"><a class="header" href="#teaching-ideas-2">Teaching Ideas</a></h2>
<ul>
<li>Add a simple built-in function (<code>length(expr)</code>) to follow the pipeline from parsing to
evaluation.</li>
<li>Implement short-circuiting or full three-valued boolean logic and validate with
sqllogictest.</li>
<li>Instrument <code>Expr::evaluate</code> with tracing to visualise expression evaluation inside
physical operators.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="query-planner-module"><a class="header" href="#query-planner-module">Query Planner Module</a></h1>
<p><code>src/plan/</code> bridges parsed SQL and executable operators. It converts the AST into a
logical plan, applies rewrites (via the optimizer), and finally emits a physical plan
(<code>PhysicalPlan</code>) that the Volcano engine can run.</p>
<hr />
<h2 id="responsibilities-3"><a class="header" href="#responsibilities-3">Responsibilities</a></h2>
<ol>
<li><strong>LogicalPlanner</strong> – walks the AST, binds table/column names using <code>PlannerContext</code>,
performs type checking, and builds a <code>LogicalPlan</code> tree.</li>
<li><strong>PlannerContext</strong> – exposes catalog lookups plus scope information for CTEs, subqueries,
and aliases.</li>
<li><strong>PhysicalPlanner</strong> – lowers an optimized <code>LogicalPlan</code> into a tree of Volcano operators.</li>
</ol>
<hr />
<h2 id="directory-layout-3"><a class="header" href="#directory-layout-3">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>logical_plan.rs</code></td><td>Logical algebra nodes.</td><td><code>LogicalPlan</code>, <code>LogicalExpr</code>, <code>JoinType</code></td></tr>
<tr><td><code>logical_planner.rs</code></td><td>AST → logical transformation.</td><td><code>LogicalPlanner</code></td></tr>
<tr><td><code>physical_plan.rs</code></td><td><code>PhysicalPlan</code> enum definition.</td><td><code>PhysicalPlan</code>, <code>Physical*</code> structs</td></tr>
<tr><td><code>physical_planner.rs</code></td><td>Logical → physical lowering.</td><td><code>PhysicalPlanner</code></td></tr>
<tr><td><code>planner_context.rs</code></td><td>Catalog/scope abstraction.</td><td><code>PlannerContext</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="workflow"><a class="header" href="#workflow">Workflow</a></h2>
<ol>
<li><strong>Name binding</strong> – <code>LogicalPlanner</code> resolves table + column references, creates
<code>TableReference</code>s, and validates schemas via the catalog.</li>
<li><strong>Logical tree</strong> – each SQL clause becomes a logical node (FROM → <code>SeqScan</code>, WHERE →
<code>Filter</code>, GROUP BY → <code>Aggregate</code>, etc.).</li>
<li><strong>Physical selection</strong> – <code>PhysicalPlanner</code> picks concrete algorithms (sequential scan,
index scan, nested-loop join, sort, limit …). Because every physical node implements
<code>VolcanoExecutor</code>, the execution engine can pull tuples immediately.</li>
</ol>
<hr />
<h2 id="interactions-3"><a class="header" href="#interactions-3">Interactions</a></h2>
<ul>
<li><strong>SQL front-end</strong> – provides the AST; helper traits (<code>NormalizedIdent</code>, etc.) keep name
resolution consistent.</li>
<li><strong>Catalog</strong> – <code>PlannerContext</code> relies on it to confirm table/index existence and fetch
schemas.</li>
<li><strong>Optimizer</strong> – operates purely on <code>LogicalPlan</code>; the planner must emit clean,
traversable trees so rules can fire.</li>
<li><strong>Execution</strong> – physical nodes carry <code>TableReference</code>, <code>SchemaRef</code>, and hints that the
execution engine passes to the storage layer.</li>
</ul>
<hr />
<h2 id="teaching-ideas-3"><a class="header" href="#teaching-ideas-3">Teaching Ideas</a></h2>
<ul>
<li>Implement a new logical operator (e.g., <code>LogicalDistinct</code>) and add the corresponding
physical operator to trace the full lifecycle.</li>
<li>Experiment with early projection inside the logical plan and observe its impact on
downstream operators.</li>
<li>Use <code>pretty_format_logical_plan</code>/<code>physical_plan</code> dumps to visualise rewrites before and
after optimizer passes.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../plan/lifecycle.html">The Lifecycle of a Query</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-lifecycle-of-a-query"><a class="header" href="#the-lifecycle-of-a-query">The Lifecycle of a Query</a></h1>
<p>When you submit a SQL query to a database, it doesn't just magically produce a result. The database undertakes a sophisticated, multi-stage process to translate the declarative SQL statement (which describes <em>what</em> data you want) into an imperative, efficient execution plan (which describes <em>how</em> to get that data). This entire process is the responsibility of the <strong>Query Planner</strong>.</p>
<p>In QuillSQL, this process follows a classic, compiler-like pipeline, which is a cornerstone of modern database architecture as taught in courses like CMU 15-445.</p>
<p>The journey from a SQL string to an executable plan involves several transformations:</p>
<p><strong>SQL String</strong> -&gt; <strong>AST (Abstract Syntax Tree)</strong> -&gt; <strong>Logical Plan</strong> -&gt; <strong>Optimized Logical Plan</strong> -&gt; <strong>Physical Plan</strong></p>
<p>Let's break down each stage.</p>
<h3 id="stage-1-parsing-sql---ast"><a class="header" href="#stage-1-parsing-sql---ast">Stage 1: Parsing (SQL -&gt; AST)</a></h3>
<p>The first step is purely syntactic. The raw SQL query string is fed into a parser. QuillSQL uses the excellent <code>sqlparser</code> crate for this. The parser checks if the SQL conforms to valid grammar and, if so, converts it into an <strong>Abstract Syntax Tree (AST)</strong>.</p>
<p>An AST is a direct tree representation of the SQL query's structure. For example, <code>SELECT id FROM users WHERE age &gt; 30</code> would be parsed into a tree structure with nodes representing the <code>SELECT</code> clause, the table <code>users</code>, the <code>WHERE</code> clause, and the predicate <code>age &gt; 30</code>.</p>
<h3 id="stage-2-logical-planning-ast---logical-plan"><a class="header" href="#stage-2-logical-planning-ast---logical-plan">Stage 2: Logical Planning (AST -&gt; Logical Plan)</a></h3>
<p>Next, the <code>LogicalPlanner</code> (<code>plan/logical_planner.rs</code>) walks the AST and converts it into a <strong>Logical Plan</strong>.</p>
<p>A Logical Plan is a tree of relational algebra operators. It describes the query in terms of high-level data operations, completely independent of how the data is stored or which algorithms will be used. It defines <em>what</em> to do, not <em>how</em> to do it.</p>
<p>Key logical operators in QuillSQL (<code>plan/logical_plan/mod.rs</code>) include:</p>
<ul>
<li><strong><code>TableScan(users)</code></strong>: Represents reading the entire <code>users</code> table.</li>
<li><strong><code>Filter(predicate: age &gt; 30)</code></strong>: Represents filtering rows based on a condition.</li>
<li><strong><code>Projection(columns: [id])</code></strong>: Represents selecting specific columns.</li>
<li><strong><code>Join</code></strong>: Represents joining two data sources.</li>
<li><strong><code>Aggregate</code></strong>: Represents a <code>GROUP BY</code> operation.</li>
<li><strong><code>Sort</code></strong>: Represents an <code>ORDER BY</code> operation.</li>
</ul>
<p>For our example query, the initial logical plan might look like this:</p>
<pre><code>Projection(columns=[id])
  └── Filter(predicate=age &gt; 30)
        └── TableScan(users)
</code></pre>
<h3 id="stage-3-logical-optimization"><a class="header" href="#stage-3-logical-optimization">Stage 3: Logical Optimization</a></h3>
<p>Before executing the plan, we have a crucial opportunity to make it more efficient. The <code>LogicalOptimizer</code> (<code>optimizer/logical_optimizer.rs</code>) takes the logical plan and applies a series of <strong>transformation rules</strong> to produce a new, equivalent logical plan that is expected to be faster.</p>
<p>QuillSQL uses a simple but effective rule-based optimizer. A classic example of such a rule is <strong>Predicate Pushdown</strong>. Consider this query:</p>
<p><code>SELECT name FROM (SELECT * FROM users JOIN cities ON users.city_id = cities.id) WHERE users.age &gt; 30;</code></p>
<p>A naive logical plan would first perform a full <code>JOIN</code> between <code>users</code> and <code>cities</code> and <em>then</em> filter the massive result. Predicate pushdown is a rule that would rewrite the plan to apply the <code>age &gt; 30</code> filter <em>before</em> the join:</p>
<p><strong>Before Optimization:</strong></p>
<pre><code>Filter(users.age &gt; 30)
  └── Join(users.city_id = cities.id)
        ├── TableScan(users)
        └── TableScan(cities)
</code></pre>
<p><strong>After Optimization (Predicate Pushdown):</strong></p>
<pre><code>Join(users.city_id = cities.id)
  ├── Filter(users.age &gt; 30)
  │     └── TableScan(users)
  └── TableScan(cities)
</code></pre>
<p>By filtering early, we dramatically reduce the number of rows that need to be processed by the expensive <code>Join</code> operator. QuillSQL implements similar rules, such as <code>PushDownLimit</code>, which pushes <code>LIMIT</code> clauses down the tree to reduce the amount of data processed.</p>
<h3 id="stage-4-physical-planning-logical-plan---physical-plan"><a class="header" href="#stage-4-physical-planning-logical-plan---physical-plan">Stage 4: Physical Planning (Logical Plan -&gt; Physical Plan)</a></h3>
<p>Finally, the <code>PhysicalPlanner</code> (<code>plan/physical_planner.rs</code>) converts the optimized logical plan into a <strong>Physical Plan</strong>.</p>
<p>A Physical Plan describes exactly <em>how</em> the query will be executed. It maps each logical operator to a concrete algorithm or implementation.</p>
<ul>
<li>A <code>LogicalPlan::TableScan</code> becomes a <code>PhysicalSeqScan</code> (a sequential scan of the table heap).</li>
<li>A <code>LogicalPlan::Filter</code> becomes a <code>PhysicalFilter</code>, which implements the filtering logic.</li>
<li>A <code>LogicalPlan::Join</code> becomes a <code>PhysicalNestedLoopJoin</code>. This is where the database commits to a specific join algorithm. A more advanced database might have multiple options (e.g., <code>PhysicalHashJoin</code>, <code>PhysicalSortMergeJoin</code>) and would use a cost model to choose the best one. QuillSQL currently implements Nested Loop Join.</li>
</ul>
<p>Each node in the physical plan tree is an executor that the <a href="plan/../modules/execution.html">Execution Engine</a> can run. This final plan is what gets executed to produce the query result.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>This layered approach—from syntax to a logical representation, then to an optimized logical representation, and finally to a concrete physical execution plan—is fundamental to database design. It provides a clear separation of concerns and, most importantly, creates a dedicated <strong>optimization stage</strong>, which is the key to achieving high performance on a wide variety of SQL queries.</p>
<hr />
<h2 id="for-study--discussion"><a class="header" href="#for-study--discussion">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Logical vs. Physical</strong>: Why is the separation between logical and physical plans so important? What would be the disadvantages of a simpler system that converted the AST directly into a physical plan?</p>
</li>
<li>
<p><strong>Join Algorithms</strong>: QuillSQL currently only implements <code>NestedLoopJoin</code>. What are two other common join algorithms? Describe how they work and in what scenarios they would be more performant than a nested loop join.</p>
</li>
<li>
<p><strong>Programming Exercise (Advanced)</strong>: Implement a <code>PhysicalHashJoin</code> operator. This is a significant undertaking that involves:
a.  Creating a <code>PhysicalHashJoin</code> struct that implements the <code>VolcanoExecutor</code> trait.
b.  In the <code>init()</code> phase, it should consume the entire "build" side (typically the smaller, right-hand table) and build an in-memory hash table from its rows.
c.  In the <code>next()</code> phase, it should read from the "probe" side (the left-hand table) one row at a time, probe the hash table for matches, and emit the joined tuples.
d.  Modify the <code>PhysicalPlanner</code> to choose <code>PhysicalHashJoin</code> instead of <code>PhysicalNestedLoopJoin</code> for equi-joins.</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Add support for the <code>UNION ALL</code> operator. This would involve:
a.  Adding a <code>Union</code> variant to the <code>LogicalPlan</code> enum.
b.  Updating the <code>LogicalPlanner</code> to recognize the <code>UNION</code> syntax in the AST and create a <code>LogicalPlan::Union</code> node.
c.  Creating a <code>PhysicalUnion</code> executor that pulls tuples from its first child until it's exhausted, and then pulls tuples from its second child.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="optimizer-module"><a class="header" href="#optimizer-module">Optimizer Module</a></h1>
<p><code>src/optimizer/</code> contains a lightweight, teaching-friendly rule engine. It rewrites
<code>LogicalPlan</code> trees into cheaper equivalents without requiring a full cost-based
framework.</p>
<hr />
<h2 id="responsibilities-4"><a class="header" href="#responsibilities-4">Responsibilities</a></h2>
<ul>
<li>Define the <code>OptimizerRule</code> trait (“match → rewrite”).</li>
<li>Ship built-in rules such as predicate pushdown, projection pruning, and limit pushdown.</li>
<li>Provide a pipeline (<code>LogicalOptimizer</code>) that repeatedly applies rules until reaching a
fixpoint, while remaining extensible for future cost models.</li>
</ul>
<hr />
<h2 id="directory-layout-4"><a class="header" href="#directory-layout-4">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>mod.rs</code></td><td>Optimizer entry point.</td><td><code>LogicalOptimizer</code></td></tr>
<tr><td><code>rule.rs</code></td><td>Trait + shared helpers.</td><td><code>OptimizerRule</code></td></tr>
<tr><td><code>rules/*</code></td><td>Concrete rewrites.</td><td><code>PushDownFilter</code>, <code>PushDownLimit</code>, …</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<ol>
<li><code>LogicalOptimizer::optimize(plan)</code> iterates through the registered rule list.</li>
<li>Each rule implements <code>fn apply(&amp;LogicalPlan) -&gt; Option&lt;LogicalPlan&gt;</code>. Returning <code>Some</code>
means the rule fired; the pipeline restarts to reach a fixpoint.</li>
<li>Rules are pure functions, which keeps them easy to unit test and reason about.</li>
</ol>
<p>Examples:</p>
<ul>
<li><strong>PushDownFilter</strong> moves filters below scans/joins to reduce input size sooner.</li>
<li><strong>PushDownLimit</strong> applies LIMIT before expensive joins/sorts when safe.</li>
<li><strong>PruneProjection</strong> removes unused columns so execution/storage decode less data.</li>
</ul>
<hr />
<h2 id="interactions-4"><a class="header" href="#interactions-4">Interactions</a></h2>
<ul>
<li><strong>LogicalPlan</strong> – the optimizer only sees logical nodes; physical/storage layers remain
untouched.</li>
<li><strong>Catalog / Statistics</strong> – current rules are heuristic, but <code>TableStatistics</code> is
available for students to experiment with cost-based decisions (e.g., choose index scan
when selectivity is low).</li>
<li><strong>Execution</strong> – leaner logical plans translate into simpler physical plans (e.g.,
predicate pushdown allows <code>PhysicalSeqScan</code> to discard rows earlier).</li>
</ul>
<hr />
<h2 id="teaching-ideas-4"><a class="header" href="#teaching-ideas-4">Teaching Ideas</a></h2>
<ul>
<li>Implement a new rule (join reordering, constant folding) and use <code>RUST_LOG=trace</code> to
compare plan dumps before/after.</li>
<li>Discuss pipeline ordering—swap rule order and observe different outcomes.</li>
<li>Prototype a tiny cost estimator using row counts from <code>TableStatistics</code> to decide on
index scans vs sequential scans.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../optimizer/rules.html">Rule-Based Optimization</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rule-based-optimization"><a class="header" href="#rule-based-optimization">Rule-Based Optimization</a></h1>
<p>After the <code>LogicalPlanner</code> creates an initial <code>LogicalPlan</code>, it's passed to the <strong><code>LogicalOptimizer</code></strong>. The initial plan is a direct, syntactically correct translation of the SQL query, but it's often not the most efficient way to execute it. The optimizer's job is to transform this plan into an equivalent, but more performant, logical plan.</p>
<h2 id="the-optimizer-in-quillsql"><a class="header" href="#the-optimizer-in-quillsql">The Optimizer in QuillSQL</a></h2>
<p>QuillSQL implements a <strong>Rule-Based Optimizer</strong>. This is a common and powerful approach where the optimizer is equipped with a set of predefined transformation rules. It repeatedly applies these rules to the logical plan tree until no more rules can be applied, or a maximum number of passes is reached.</p>
<p>The main components are:</p>
<ul>
<li><strong><code>LogicalOptimizer</code> (<code>optimizer/logical_optimizer.rs</code>)</strong>: The main driver. It holds a list of rules and contains the logic to recursively walk the plan tree and apply them.</li>
<li><strong><code>LogicalOptimizerRule</code> Trait</strong>: An interface that every optimization rule must implement. Its core method is <code>try_optimize</code>, which takes a plan node and attempts to return a rewritten, optimized version of that node.</li>
</ul>
<h2 id="deep-dive-the-pushdownlimit-rule"><a class="header" href="#deep-dive-the-pushdownlimit-rule">Deep Dive: The <code>PushDownLimit</code> Rule</a></h2>
<p>One of the most classic and effective optimizations is "pushing down" operations as far as possible towards the data source. Let's examine the <code>PushDownLimit</code> rule (<code>optimizer/rule/push_down_limit.rs</code>) to see this in action.</p>
<p>Consider the following query:</p>
<pre><code class="language-sql">SELECT * FROM users ORDER BY signup_date LIMIT 10;
</code></pre>
<h4 id="the-naive-plan"><a class="header" href="#the-naive-plan">The Naive Plan</a></h4>
<p>A naive logical plan for this query would be:</p>
<pre><code>Limit(10)
  └── Sort(by: signup_date)
        └── TableScan(users)
</code></pre>
<p>If executed directly, this plan would:</p>
<ol>
<li>Scan the <em>entire</em> <code>users</code> table.</li>
<li>Sort the <em>entire</em> table by <code>signup_date</code>.</li>
<li>Finally, discard all but the first 10 rows.</li>
</ol>
<p>This is incredibly inefficient, especially for a large table, as it involves a massive, memory-intensive sort operation.</p>
<h4 id="the-optimization-rule"><a class="header" href="#the-optimization-rule">The Optimization Rule</a></h4>
<p>The <code>PushDownLimit</code> rule is designed to recognize this specific pattern: a <code>Limit</code> operator directly on top of a <code>Sort</code> operator.</p>
<p>When the optimizer applies this rule, the <code>try_optimize</code> method matches on the <code>Limit</code> node. It inspects its child and sees that it's a <code>Sort</code> node. The rule then knows it can apply its logic.</p>
<h4 id="the-rewritten-plan"><a class="header" href="#the-rewritten-plan">The Rewritten Plan</a></h4>
<p>The rule rewrites the plan tree by "pushing" the limit information <em>into</em> the <code>Sort</code> node itself:</p>
<pre><code>Limit(10)
  └── Sort(by: signup_date, limit: 10)
        └── TableScan(users)
</code></pre>
<p>Notice the new <code>limit: 10</code> property on the <code>Sort</code> node. This seemingly small change has a huge performance impact. When the <code>PhysicalSort</code> operator is created from this logical node, it now knows that it only needs to find the top 10 rows. Instead of performing a full sort, it can use a much more efficient algorithm, like a <strong>heap sort (using a min-heap of size 10)</strong>, to find the top 10 rows in a single pass over the data.</p>
<p>This optimization avoids sorting the entire table, dramatically reducing both CPU and memory consumption.</p>
<h2 id="other-rules"><a class="header" href="#other-rules">Other Rules</a></h2>
<p>QuillSQL implements other simple but effective rules:</p>
<ul>
<li><strong><code>EliminateLimit</code></strong>: Removes a <code>LIMIT</code> clause if it provides no value (e.g., <code>LIMIT NULL</code>).</li>
<li><strong><code>MergeLimit</code></strong>: If two <code>LIMIT</code> clauses are stacked on top of each other (which can happen after other rule transformations), this rule merges them into a single, more restrictive <code>LIMIT</code>.</li>
</ul>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>While QuillSQL's optimizer is currently rule-based and relatively simple, it demonstrates the fundamental principles of query optimization. By separating the logical representation of a query from its physical execution and applying equivalence-preserving transformations, a database can achieve massive performance gains. More advanced systems build on this with a <strong>Cost-Based Optimizer</strong>, which uses table statistics to estimate the "cost" of different physical plans (e.g., choosing between a <code>NestedLoopJoin</code> and a <code>HashJoin</code>) and pick the cheapest one.</p>
<hr />
<h2 id="for-study--discussion-1"><a class="header" href="#for-study--discussion-1">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Rule Ordering</strong>: The <code>LogicalOptimizer</code> applies its list of rules in a fixed order for a set number of passes. Can the order in which rules are applied affect the final, optimized plan? Can one rule's transformation enable another rule to be applied in a subsequent pass?</p>
</li>
<li>
<p><strong>Cost-Based vs. Rule-Based</strong>: What is the primary limitation of a purely rule-based optimizer? When would a rule-based optimizer make a poor decision that a cost-based optimizer (with accurate statistics) would get right? (Hint: consider join algorithm selection).</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Implement the classic <strong>Predicate Pushdown</strong> rule. Your rule should look for a <code>Filter</code> operator whose child is a <code>Join</code>. If the filter's predicate only uses columns from one side of the join, the rule should push the <code>Filter</code> node down to that side of the join, below the <code>Join</code> node. This is one of the most effective optimizations in any database.</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Implement a <strong>Constant Folding</strong> rule. This rule would traverse expression trees and pre-compute constant expressions. For example:</p>
<ul>
<li>An expression <code>WHERE age = 10 + 5</code> would be rewritten to <code>WHERE age = 15</code>.</li>
<li>An expression <code>WHERE 1 = 1</code> would be evaluated to <code>true</code>, and a smart optimizer could then potentially eliminate the <code>WHERE</code> clause entirely.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="execution-engine"><a class="header" href="#execution-engine">Execution Engine</a></h1>
<p><code>src/execution/</code> drives <code>PhysicalPlan</code> trees using the Volcano (iterator) model. Every
operator pulls tuples from its children, coordinating closely with transactions,
storage, and expression evaluation.</p>
<hr />
<h2 id="core-components"><a class="header" href="#core-components">Core Components</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Role</th></tr></thead><tbody>
<tr><td><code>PhysicalPlan</code></td><td>Enum covering all physical operators; each implements <code>VolcanoExecutor</code>.</td></tr>
<tr><td><code>ExecutionContext</code></td><td>Shared context carrying the catalog, <code>TxnContext</code>, storage engine, and expression helpers.</td></tr>
<tr><td><code>TupleStream</code></td><td>Unified scan interface returned by table/index handles.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="execution-flow"><a class="header" href="#execution-flow">Execution Flow</a></h2>
<ol>
<li><code>ExecutionEngine::execute</code> calls <code>init</code> on the root plan (and recursively on children).</li>
<li>The engine loops calling <code>next</code>, with parents pulling tuples from children.</li>
<li><code>ExecutionContext</code> supplies transaction snapshots, lock helpers, and expression
evaluation per call.</li>
<li>Once <code>next</code> returns <code>None</code>, the accumulated results are returned to the caller (CLI,
HTTP API, or tests).</li>
</ol>
<hr />
<h2 id="operator-examples"><a class="header" href="#operator-examples">Operator Examples</a></h2>
<ul>
<li><strong>PhysicalSeqScan</strong> – acquires a <code>table_stream</code> from the storage engine, uses
<code>ScanPrefetch</code> for batching, and relies on <code>TxnContext::read_visible_tuple</code> for MVCC.</li>
<li><strong>PhysicalIndexScan</strong> – uses <code>index_stream</code>, tracks <code>invisible_hits</code>, and notifies the
catalog when garbage accumulates.</li>
<li><strong>PhysicalUpdate/PhysicalDelete</strong> – call <code>prepare_row_for_write</code> to re-validate locks
and the latest tuple before invoking <code>apply_update/delete</code>.</li>
<li><strong>PhysicalNestedLoopJoin</strong> – showcases the parent/child pull loop and acts as a baseline
for more advanced joins.</li>
</ul>
<hr />
<h2 id="interactions-5"><a class="header" href="#interactions-5">Interactions</a></h2>
<ul>
<li><strong>StorageEngine</strong> – all data access goes through handles/streams, keeping execution
storage-agnostic.</li>
<li><strong>Transaction</strong> – <code>TxnContext</code> enforces locking, snapshots, and undo logging; operators
never talk to <code>LockManager</code> directly.</li>
<li><strong>Expression</strong> – <code>ExecutionContext::eval_expr</code> / <code>eval_predicate</code> evaluate expressions
built by the planner.</li>
<li><strong>Optimizer/Planner</strong> – execution honours the plan as-is; all structural choices happen
upstream.</li>
</ul>
<hr />
<h2 id="teaching-ideas-5"><a class="header" href="#teaching-ideas-5">Teaching Ideas</a></h2>
<ul>
<li>Implement a new operator (e.g., <code>PhysicalMergeJoin</code>) to see how <code>ExecutionContext</code>
support generalises.</li>
<li>Add adaptive prefetching inside <code>PhysicalSeqScan</code> to explore iterator hints.</li>
<li>Enable <code>RUST_LOG=execution=trace</code> to watch the <code>init</code>/<code>next</code> call sequence during a
query.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../execution/volcano.html">The Volcano Execution Model</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-volcano-execution-model"><a class="header" href="#the-volcano-execution-model">The Volcano Execution Model</a></h1>
<p>Once the <a href="execution/../modules/plan.html">Query Planner</a> has produced an optimized <code>PhysicalPlan</code>, it's the job of the <strong>Execution Engine</strong> to run it and produce results. The execution engine is the component that brings the plan to life, interacting with the transaction manager and storage layer to process data.</p>
<p>QuillSQL uses the classic <strong>Volcano Model</strong>, also known as the <strong>Iterator Model</strong>. This is a pull-based execution model where each physical operator in the plan tree acts as an iterator that the parent operator can "pull" rows from.</p>
<h2 id="1-the-volcanoexecutor-trait"><a class="header" href="#1-the-volcanoexecutor-trait">1. The <code>VolcanoExecutor</code> Trait</a></h2>
<p>At the heart of the execution model is the <code>VolcanoExecutor</code> trait (<code>execution/mod.rs</code>). Every physical operator implements this simple trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait VolcanoExecutor {
    fn init(&amp;self, context: &amp;mut ExecutionContext) -&gt; QuillSQLResult&lt;()&gt;;
    fn next(&amp;self, context: &amp;mut ExecutionContext) -&gt; QuillSQLResult&lt;Option&lt;Tuple&gt;&gt;;
    fn output_schema(&amp;self) -&gt; SchemaRef;
}
<span class="boring">}</span></code></pre></pre>
<ul>
<li><strong><code>init()</code></strong>: This method is called once at the beginning of execution. It allows an operator to set up its initial state (e.g., a <code>SeqScan</code> operator would initialize its table iterator here).</li>
<li><strong><code>next()</code></strong>: This is the core method. When called, the operator produces its next output tuple. It returns <code>Some(tuple)</code> if it has a row, or <code>None</code> if it has exhausted its data source. The top-level <code>ExecutionEngine</code> simply calls <code>next()</code> on the root of the plan tree in a loop until it receives <code>None</code>.</li>
</ul>
<h2 id="2-the-executioncontext"><a class="header" href="#2-the-executioncontext">2. The <code>ExecutionContext</code></a></h2>
<p>Notice that both <code>init()</code> and <code>next()</code> take a mutable <code>ExecutionContext</code>. This object is the "context" or "world" in which the query runs. It is passed down the entire operator tree and gives each operator access to crucial services:</p>
<ul>
<li><strong><code>Catalog</code></strong>: To look up tables and indexes.</li>
<li><strong><code>TransactionManager</code> and <code>Transaction</code></strong>: To interact with the current transaction. This is how operators perform locking and visibility checks.</li>
<li><strong><code>MvccSnapshot</code></strong>: The specific MVCC snapshot for the current transaction, used to determine which tuple versions are visible.</li>
<li><strong><code>StorageEngine</code></strong>: A pluggable trait that hides TableHeap/B+Tree specifics.</li>
<li><strong>Helper APIs</strong>: See below.</li>
</ul>
<h3 id="executioncontext-helper-apis"><a class="header" href="#executioncontext-helper-apis">ExecutionContext helper APIs</a></h3>
<p>To keep physical operators tiny, QuillSQL exposes a few battle-tested helpers:</p>
<ul>
<li><code>read_visible_tuple(table, rid, meta, tuple)</code> performs the MVCC visibility check and acquires the correct shared locks for the current isolation level.</li>
<li><code>prepare_row_for_write</code> / <code>apply_update</code> / <code>apply_delete</code> take care of X locks, re-reading the latest version, index maintenance, and undo logging for UPDATE/DELETE.</li>
<li><code>insert_tuple_with_indexes</code> inserts into the heap <strong>and</strong> updates every index in one call.</li>
<li><code>eval_predicate</code> / <code>eval_expr</code> encapsulate expression evaluation (and boolean coercion), so operators never have to fiddle with <code>ScalarValue</code>.</li>
<li>DDL helpers (<code>create_table</code>, <code>drop_table</code>, <code>create_index</code>, …) proxy the catalog so CREATE/DROP operators stay declarative.</li>
</ul>
<p>All of these helpers delegate to the storage engine. By default we ship a TableHeap+B+Tree engine, but research exercises can implement their own engine and plug it into the context without modifying operators.</p>
<p>This design cleanly separates the operator's logic from the transactional context it runs in.</p>
<h2 id="3-anatomy-of-physical-operators"><a class="header" href="#3-anatomy-of-physical-operators">3. Anatomy of Physical Operators</a></h2>
<p>Data flows <em>up</em> the tree from the leaves (scans) to the root. Let's see how it works by examining a few key operators.</p>
<h3 id="leaf-operator-physicalseqscan"><a class="header" href="#leaf-operator-physicalseqscan">Leaf Operator: <code>PhysicalSeqScan</code></a></h3>
<p>A sequential scan is at the leaf of a plan tree. It's responsible for reading tuples from a table on disk.</p>
<ul>
<li><strong><code>init()</code></strong>: It acquires an <code>IntentionShared</code> lock on the table and creates a <code>TableIterator</code> for the table heap.</li>
<li><strong><code>next()</code></strong>: In a loop, it does the following:
<ol>
<li>Pulls the next raw tuple <code>(rid, meta, tuple)</code> from the <code>TableIterator</code>.</li>
<li>Calls <code>context.is_visible(&amp;meta)</code> to perform an <strong>MVCC visibility check</strong> using the transaction's snapshot.</li>
<li>If the tuple version is visible, it acquires the necessary row lock (e.g., <code>Shared</code> lock) and returns the tuple.</li>
<li>If the tuple is not visible, it ignores it and loops to get the next one.</li>
</ol>
</li>
</ul>
<h3 id="unary-operator-physicalfilter"><a class="header" href="#unary-operator-physicalfilter">Unary Operator: <code>PhysicalFilter</code></a></h3>
<p>A filter has one child operator (its <code>input</code>). It implements a <code>WHERE</code> clause.</p>
<ul>
<li><strong><code>next()</code></strong>: Its logic is a simple, tight loop:
<ol>
<li>It calls <code>self.input.next()</code> to get a tuple from its child.</li>
<li>If the child returns <code>None</code>, the filter is also exhausted and returns <code>None</code>.</li>
<li>If it receives a tuple, it evaluates its predicate expression (e.g., <code>age &gt; 30</code>) against the tuple.</li>
<li>If the predicate evaluates to <code>true</code>, it returns the tuple. Otherwise, it loops back to step 1.</li>
</ol>
</li>
</ul>
<h3 id="binary-operator-physicalnestedloopjoin"><a class="header" href="#binary-operator-physicalnestedloopjoin">Binary Operator: <code>PhysicalNestedLoopJoin</code></a></h3>
<p>A join has two children: a left (outer) and a right (inner).</p>
<ul>
<li><strong><code>next()</code></strong>: It implements the classic nested loop join algorithm:
<ol>
<li>Fetch one tuple from the <strong>outer</strong> (left) child and hold onto it.</li>
<li>Enter a loop: fetch tuples one by one from the <strong>inner</strong> (right) child.</li>
<li>For each inner tuple, combine it with the held outer tuple and evaluate the join condition. If it matches, return the combined tuple.</li>
<li>When the inner child is exhausted, <strong>rewind it</strong> by calling <code>self.right_input.init()</code> again.</li>
<li>Go back to step 1 to fetch the <em>next</em> tuple from the outer child.</li>
<li>Repeat until the outer child is also exhausted.</li>
</ol>
</li>
</ul>
<h2 id="4-putting-it-all-together"><a class="header" href="#4-putting-it-all-together">4. Putting It All Together</a></h2>
<p>Consider the query <code>SELECT name FROM users WHERE age &gt; 30</code>. The physical plan is <code>Projection -&gt; Filter -&gt; SeqScan</code>.</p>
<ol>
<li>The <code>ExecutionEngine</code> calls <code>next()</code> on the <code>Projection</code> operator.</li>
<li>The <code>Projection</code> operator needs a tuple, so it calls <code>next()</code> on its child, <code>Filter</code>.</li>
<li>The <code>Filter</code> operator needs a tuple, so it calls <code>next()</code> on its child, <code>SeqScan</code>.</li>
<li>The <code>SeqScan</code> operator fetches a raw tuple from the <code>TableHeap</code>, checks its MVCC visibility, and finds a visible tuple for a user with <code>age = 25</code>.</li>
<li><code>SeqScan</code> returns this tuple up to <code>Filter</code>.</li>
<li><code>Filter</code> evaluates <code>age &gt; 30</code> on the tuple. It's false, so it loops, calling <code>SeqScan.next()</code> again.</li>
<li><code>SeqScan</code> finds another visible tuple, this time for a user with <code>age = 40</code> and <code>name = 'Alice'</code>.</li>
<li><code>SeqScan</code> returns this tuple up to <code>Filter</code>.</li>
<li><code>Filter</code> evaluates <code>age &gt; 30</code>. It's true! It returns the tuple for Alice up to <code>Projection</code>.</li>
<li><code>Projection</code> takes the full tuple for Alice, creates a new tuple containing only the <code>name</code> column (<code>'Alice'</code>), and returns this new tuple as the result.</li>
</ol>
<p>This process repeats, with tuples flowing up the tree one at a time, until the <code>SeqScan</code> operator runs out of pages and returns <code>None</code>, which then propagates up the tree, signaling the end of execution.</p>
<hr />
<h2 id="for-study--discussion-2"><a class="header" href="#for-study--discussion-2">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Push vs. Pull Models</strong>: The Volcano model is a "pull-based" model. An alternative is a "push-based" model, where operators push their results to their parents as soon as they are ready. What are the potential advantages and disadvantages of each model, particularly concerning cache efficiency and control flow?</p>
</li>
<li>
<p><strong>Blocking vs. Non-Blocking Operators</strong>: Some operators, like <code>PhysicalFilter</code>, can produce their first output row as soon as they receive their first input row. These are <strong>non-blocking</strong>. Other operators, like <code>PhysicalSort</code>, must consume their <em>entire</em> input before they can produce even a single row of output. These are <strong>blocking</strong>. What is the impact of blocking operators on query latency and memory usage?</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: The current <code>PhysicalNestedLoopJoin</code> is simple but can be inefficient as it re-scans the entire inner table for every outer row. Implement a <code>PhysicalBlockNestedLoopJoin</code> operator. This version would read a <em>block</em> (a small batch) of tuples from the outer table into an in-memory buffer, and then iterate through the inner table once for that entire block. This can significantly reduce the number of times the inner table needs to be scanned.</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Implement the <code>PhysicalLimit</code> operator. Its <code>next()</code> method should:
a.  Keep an internal counter.
b.  If the counter is less than the <code>offset</code>, pull and discard tuples from its child.
c.  If the counter is between <code>offset</code> and <code>offset + limit</code>, pull a tuple from its child and return it.
d.  Once the limit is reached, it should stop pulling from its child and return <code>None</code> for all subsequent calls. This is important for efficiency, as it stops the execution of the entire sub-tree below it.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transaction-module"><a class="header" href="#transaction-module">Transaction Module</a></h1>
<p><code>src/transaction/</code> enforces the Atomicity and Isolation parts of ACID. It combines MVCC
with strict two-phase locking so reads and writes can proceed concurrently without
violating correctness.</p>
<hr />
<h2 id="main-components"><a class="header" href="#main-components">Main Components</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Role</th></tr></thead><tbody>
<tr><td><code>TransactionManager</code></td><td>Creates/commits/aborts transactions, assigns txn &amp; command ids, coordinates WAL.</td></tr>
<tr><td><code>Transaction</code></td><td>Stores state, held locks, undo chain, and cached snapshot.</td></tr>
<tr><td><code>TxnContext</code> / <code>TxnRuntime</code></td><td>Execution-time wrapper exposing MVCC + locking helpers.</td></tr>
<tr><td><code>LockManager</code></td><td>Multi-granularity locking (IS/IX/S/SIX/X) with deadlock detection.</td></tr>
<tr><td><code>TransactionSnapshot</code></td><td>Tracks <code>xmin/xmax/active_txns</code> for visibility checks.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="workflow-1"><a class="header" href="#workflow-1">Workflow</a></h2>
<ol>
<li><code>SessionContext</code> calls <code>TransactionManager::begin</code> to create a transaction.</li>
<li>Each SQL statement builds a <code>TxnRuntime</code>, yielding a fresh command id and snapshot.</li>
<li>Operators call <code>TxnContext::lock_table/lock_row</code> to obey strict 2PL.</li>
<li><code>TableHandle::insert/delete/update</code> records undo, acquires locks, and emits WAL via
<code>TxnContext</code>.</li>
<li>Commit: write a <code>Commit</code> record → flush depending on <code>synchronous_commit</code> → release
locks.</li>
<li>Abort: walk the undo list, write CLRs, restore heap/index state, release locks.</li>
</ol>
<hr />
<h2 id="mvcc-details"><a class="header" href="#mvcc-details">MVCC Details</a></h2>
<ul>
<li><code>TupleMeta</code> stores inserting/deleting txn ids and command ids. <code>read_visible_tuple</code>
checks snapshots and, if needed, rewinds to the latest visible version.</li>
<li>Isolation levels:
<ul>
<li><strong>Read Uncommitted</strong> – minimal snapshot caching.</li>
<li><strong>Read Committed</strong> – refresh snapshot each command to avoid dirty reads.</li>
<li><strong>Repeatable Read / Serializable</strong> – capture the snapshot once; RR releases shared
locks at statement end, Serializable holds them to commit to avoid phantoms.</li>
</ul>
</li>
<li>UPDATE skips versions created by the same <code>(txn_id, command_id)</code> to avoid looping back
over freshly inserted tuples.</li>
</ul>
<hr />
<h2 id="locking"><a class="header" href="#locking">Locking</a></h2>
<ul>
<li>Multi-granularity hierarchy: table-level IS/IX/S/SIX/X plus row-level S/X.</li>
<li>Deadlock detection: <code>LockManager</code> maintains a wait-for graph and periodically chooses a
victim (usually the longest waiter).</li>
<li>Release policy: exclusive/intent locks stay until commit; RR drops shared row locks at
statement end, Serializable waits until commit.</li>
</ul>
<hr />
<h2 id="interactions-6"><a class="header" href="#interactions-6">Interactions</a></h2>
<ul>
<li><strong>ExecutionContext</strong> – all helpers (lock acquisition, visibility checks, undo logging)
are exposed here, so physical operators never touch <code>LockManager</code> directly.</li>
<li><strong>StorageEngine</strong> – handles call <code>TxnContext</code> before mutating heaps/indexes; MVCC metadata
lives in <code>TupleMeta</code>.</li>
<li><strong>Recovery</strong> – Begin/Commit/Abort records emitted here drive ARIES undo/redo.</li>
<li><strong>Background</strong> – MVCC vacuum reads <code>TransactionManager::oldest_active_txn()</code> to compute
<code>safe_xmin</code>.</li>
</ul>
<hr />
<h2 id="teaching-ideas-6"><a class="header" href="#teaching-ideas-6">Teaching Ideas</a></h2>
<ul>
<li>Change <code>DatabaseOptions::default_isolation_level</code> and compare SELECT behaviour under
RC vs RR.</li>
<li>Write a unit test that deadlocks two transactions and watch <code>LockManager</code> pick a victim.</li>
<li>Implement statement-level snapshot refresh or Serializable Snapshot Isolation (SSI) as
an advanced exercise.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../transaction/mvcc_and_2pl.html">MVCC and 2PL</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mvcc-and-2pl"><a class="header" href="#mvcc-and-2pl">MVCC and 2PL</a></h1>
<p>Of the four ACID properties, <strong>Isolation</strong> is often the most complex to implement. It ensures that concurrent transactions do not interfere with each other, making it appear as if each transaction is executing sequentially, one after another. Without proper isolation, a database would suffer from concurrency-related anomalies like dirty reads, non-repeatable reads, and phantom reads.</p>
<p>Databases typically use two main strategies for concurrency control:</p>
<ol>
<li><strong>Pessimistic Concurrency Control</strong>: Assumes conflicts are likely and prevents them from happening by using locks. The most common protocol is <strong>Two-Phase Locking (2PL)</strong>.</li>
<li><strong>Optimistic Concurrency Control</strong>: Assumes conflicts are rare. Transactions proceed without locking, and the database validates at commit time that no conflicts occurred. A popular variant is <strong>Multi-Version Concurrency Control (MVCC)</strong>.</li>
</ol>
<p>QuillSQL, like many modern relational databases (e.g., PostgreSQL, Oracle), implements a powerful <strong>hybrid model that combines MVCC with 2PL</strong>.</p>
<h2 id="1-mvcc-reading-without-blocking"><a class="header" href="#1-mvcc-reading-without-blocking">1. MVCC: Reading without Blocking</a></h2>
<p>The core idea of MVCC is <strong>"writers don't block readers, and readers don't block writers."</strong> This is achieved by never overwriting data in-place. When a row is updated, the database creates a <em>new version</em> of that row, preserving the old one.</p>
<h3 id="version-chains-and-tuplemeta"><a class="header" href="#version-chains-and-tuplemeta">Version Chains and <code>TupleMeta</code></a></h3>
<p>As discussed in the <a href="transaction/../storage/table_heap.html">Storage Engine</a> chapter, every tuple on disk has associated metadata (<code>TupleMeta</code>) that includes:</p>
<ul>
<li><code>insert_txn_id</code>: The ID of the transaction that created this version.</li>
<li><code>delete_txn_id</code>: The ID of the transaction that marked this version as deleted.</li>
<li><code>prev_version</code> / <code>next_version</code>: Pointers (RIDs) that form a linked list of versions for a single logical row, called the <strong>version chain</strong>.</li>
</ul>
<h3 id="transaction-snapshots"><a class="header" href="#transaction-snapshots">Transaction Snapshots</a></h3>
<p>When a transaction begins, it asks the <code>TransactionManager</code> for a <strong>snapshot</strong> of the database state. This snapshot, defined in <code>transaction/mvcc.rs</code>, contains three key pieces of information:</p>
<ul>
<li><code>xmin</code>: The oldest active transaction ID at the time of the snapshot. Any transaction with an ID less than <code>xmin</code> is guaranteed to be either committed or aborted.</li>
<li><code>xmax</code>: The next transaction ID to be assigned. Any transaction with an ID greater than or equal to <code>xmax</code> was not yet started when the snapshot was taken.</li>
<li><code>active_txns</code>: A list of all other transaction IDs that were active when the snapshot was taken.</li>
</ul>
<h3 id="the-visibility-check"><a class="header" href="#the-visibility-check">The Visibility Check</a></h3>
<p>When a transaction scans the database, for every tuple version it encounters, it performs a <strong>visibility check</strong> using its snapshot. The logic in <code>MvccSnapshot::is_visible</code> determines if the version should be "seen" by the current transaction. In simplified terms, a tuple version is visible if:</p>
<ol>
<li>Its <code>insert_txn_id</code> belongs to a transaction that was already committed before our snapshot was taken.</li>
<li><strong>AND</strong> its <code>delete_txn_id</code> is either not set, OR it belongs to a transaction that was not yet committed when our snapshot was taken.</li>
</ol>
<p>This mechanism elegantly solves several concurrency problems. Since a reader transaction only ever sees a consistent snapshot of the database, it is completely immune to changes being made by other concurrent writer transactions. This prevents dirty reads and non-repeatable reads.</p>
<h2 id="2-two-phase-locking-2pl-preventing-write-write-conflicts"><a class="header" href="#2-two-phase-locking-2pl-preventing-write-write-conflicts">2. Two-Phase Locking (2PL): Preventing Write-Write Conflicts</a></h2>
<p>While MVCC is excellent for read-write conflicts, it does not, by itself, prevent two transactions from trying to modify the same logical row at the same time (a write-write conflict). This is where locking comes in.</p>
<p>QuillSQL implements a strict <strong>Two-Phase Locking</strong> protocol via the <code>LockManager</code> (<code>transaction/lock_manager.rs</code>).</p>
<h3 id="the-two-phases"><a class="header" href="#the-two-phases">The Two Phases</a></h3>
<ol>
<li><strong>Growing Phase</strong>: The transaction can acquire new locks as it executes.</li>
<li><strong>Shrinking Phase</strong>: Once the transaction releases its first lock, it cannot acquire any new locks.</li>
</ol>
<p>In practice, QuillSQL uses <strong>Strict 2PL</strong>, where the shrinking phase is delayed until the transaction commits or aborts. All locks are held until the very end.</p>
<h3 id="hierarchical-locking-intention-locks"><a class="header" href="#hierarchical-locking-intention-locks">Hierarchical Locking (Intention Locks)</a></h3>
<p>To be efficient, the <code>LockManager</code> uses a multi-granularity, hierarchical locking scheme. Before a transaction can take a fine-grained lock on a row (a <code>Shared</code> or <code>Exclusive</code> lock), it must first acquire a coarser-grained <strong>intention lock</strong> on the table.</p>
<ul>
<li><strong><code>IntentionShared (IS)</code></strong>: Signals the intent to read rows from the table.</li>
<li><strong><code>IntentionExclusive (IX)</code></strong>: Signals the intent to modify rows in the table.</li>
</ul>
<p>This prevents a transaction wanting to lock the entire table from conflicting with another transaction that is already modifying a single row. For example, a <code>SELECT * FROM users FOR UPDATE</code> (which needs an <code>X</code> lock on the table) will be blocked if another transaction already holds an <code>IX</code> lock on <code>users</code>.</p>
<h3 id="deadlock-detection"><a class="header" href="#deadlock-detection">Deadlock Detection</a></h3>
<p>When two or more transactions are waiting for each other to release locks in a circular chain, a <strong>deadlock</strong> occurs. The <code>LockManager</code> detects this by building a <strong>waits-for graph</strong>. When a transaction <code>T1</code> has to wait for a lock held by <code>T2</code>, an edge <code>T1 -&gt; T2</code> is added to the graph. If adding an edge creates a cycle, a deadlock is detected, and one of the transactions (the victim) is immediately aborted to break the cycle.</p>
<h2 id="3-the-hybrid-model-mvcc--2pl-in-action"><a class="header" href="#3-the-hybrid-model-mvcc--2pl-in-action">3. The Hybrid Model: MVCC + 2PL in Action</a></h2>
<p>In QuillSQL, these two mechanisms work in concert:</p>
<ul>
<li>
<p>A <strong>reader</strong> (<code>SELECT</code>) transaction acquires an MVCC snapshot. It uses this snapshot to determine visibility. It only needs to acquire <code>Shared</code> (S) locks on the rows it reads to prevent other transactions from modifying them, thus ensuring repeatable reads in higher isolation levels.</p>
</li>
<li>
<p>A <strong>writer</strong> (<code>UPDATE</code>, <code>DELETE</code>) transaction must acquire an <code>Exclusive</code> (X) lock on the specific row it intends to modify. Once the lock is granted, it knows no other writer can interfere. It can then safely create a new tuple version as part of the MVCC protocol.</p>
</li>
</ul>
<p>This hybrid approach provides the best of both worlds: reads are fast and non-blocking, while write-write conflicts are safely prevented by the locking protocol.</p>
<hr />
<h2 id="for-study--discussion-3"><a class="header" href="#for-study--discussion-3">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Isolation Levels</strong>: QuillSQL supports multiple SQL isolation levels. How does the behavior of MVCC snapshots and 2PL change between <code>ReadCommitted</code> and <code>RepeatableRead</code>? In <code>ReadCommitted</code>, a transaction gets a new snapshot for every statement, whereas in <code>RepeatableRead</code>, it uses the same snapshot for the entire transaction. What concurrency anomalies does this difference prevent?</p>
</li>
<li>
<p><strong>Phantom Reads</strong>: Even with MVCC and row-level 2PL, a <code>RepeatableRead</code> transaction can suffer from <em>phantom reads</em>. Imagine <code>T1</code> runs <code>SELECT COUNT(*) FROM users WHERE age &gt; 30</code>. Then, <code>T2</code> inserts a new user with <code>age = 40</code> and commits. If <code>T1</code> runs its <code>SELECT</code> query again, it will see a new "phantom" row that wasn't there before. How can a database prevent this to achieve the <code>Serializable</code> isolation level? (Hint: research predicate locking and index-range locking).</p>
</li>
<li>
<p><strong>Deadlock Handling</strong>: QuillSQL detects deadlocks by building a waits-for graph and aborting a transaction. What is an alternative strategy for handling deadlocks? For example, what are the pros and cons of using lock timeouts instead of cycle detection?</p>
</li>
<li>
<p><strong>Programming Exercise (Advanced)</strong>: A full implementation of <code>Serializable</code> isolation often requires index-range locking to prevent phantoms. Extend the <code>LockManager</code> to support locking a <em>range</em> of keys within a B+Tree index. This would require a new lock type and a way to check for overlapping ranges. When a <code>SELECT ... WHERE age &gt; 30</code> query runs, it would place a shared lock on the <code>(30, +∞)</code> range in the index on the <code>age</code> column, preventing any other transaction from inserting a new user with an age in that range.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="storage-engine"><a class="header" href="#storage-engine">Storage Engine</a></h1>
<p>The storage engine persists relational data, covering heap files, indexes, page formats,
and the handles exposed to execution. Understanding this layer is key to reasoning about
performance, MVCC, and recovery.</p>
<hr />
<h2 id="responsibilities-5"><a class="header" href="#responsibilities-5">Responsibilities</a></h2>
<ul>
<li>Manage <code>TableHeap</code> insert/delete/update paths and their MVCC metadata.</li>
<li>Maintain indexes (see the <a href="modules/./index.html">Index module</a> for details).</li>
<li>Expose the <code>StorageEngine</code> trait so execution can fetch <code>TableHandle</code> / <code>IndexHandle</code>
instances per table.</li>
<li>Provide <code>TupleStream</code> so sequential and index scans share a unified interface.</li>
</ul>
<hr />
<h2 id="directory-layout-5"><a class="header" href="#directory-layout-5">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Purpose</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>engine.rs</code></td><td>Default engine plus handle definitions.</td><td><code>StorageEngine</code>, <code>TableHandle</code>, <code>TupleStream</code>, <code>ScanOptions</code></td></tr>
<tr><td><code>table_heap/</code></td><td>Heap storage + MVCC logic.</td><td><code>TableHeap</code>, <code>MvccHeap</code></td></tr>
<tr><td><code>index/</code></td><td>B+Tree implementation.</td><td><code>BPlusTreeIndex</code></td></tr>
<tr><td><code>page/</code></td><td>Page, RID, tuple metadata.</td><td><code>Page</code>, <code>RecordId</code>, <code>TupleMeta</code></td></tr>
<tr><td><code>tuple/</code></td><td>Row encoding and projection helpers.</td><td><code>Tuple</code></td></tr>
<tr><td><code>disk_manager.rs</code></td><td>File layout and page I/O.</td><td><code>DiskManager</code></td></tr>
<tr><td><code>disk_scheduler.rs</code></td><td><code>io_uring</code>-backed async scheduler.</td><td><code>DiskScheduler</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="core-abstractions"><a class="header" href="#core-abstractions">Core Abstractions</a></h2>
<h3 id="storageengine-trait"><a class="header" href="#storageengine-trait">StorageEngine Trait</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait StorageEngine {
    fn table(&amp;self, catalog: &amp;Catalog, table: &amp;TableReference)
        -&gt; QuillSQLResult&lt;Arc&lt;dyn TableHandle&gt;&gt;;
    fn indexes(&amp;self, catalog: &amp;Catalog, table: &amp;TableReference)
        -&gt; QuillSQLResult&lt;Vec&lt;Arc&lt;dyn IndexHandle&gt;&gt;&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>The default implementation wraps the row-oriented heap + B+Tree combo, but the trait is
ready for column stores, remote storage, or async engines.</p>
<h3 id="tablehandle"><a class="header" href="#tablehandle">TableHandle</a></h3>
<p>Offers <code>full_scan(ScanOptions)</code>, <code>insert</code>, <code>delete</code>, <code>update</code>, and
<code>prepare_row_for_write</code>. MVCC, undo, and locking concerns live here so execution operators
only describe intent.</p>
<h3 id="tuplestream"><a class="header" href="#tuplestream">TupleStream</a></h3>
<p>Minimal iterator that returns <code>(RecordId, TupleMeta, Tuple)</code> triples. <code>ScanOptions</code> carry
streaming hints, projection lists, or batch sizes; index scans use <code>IndexScanRequest</code> to
describe ranges.</p>
<hr />
<h2 id="interactions-7"><a class="header" href="#interactions-7">Interactions</a></h2>
<ul>
<li><strong>Execution</strong> – <code>ExecutionContext::table_stream</code> / <code>index_stream</code> delegate to handles.</li>
<li><strong>Transaction</strong> – Handle methods call into <code>TxnContext</code> to acquire locks, record undo,
and emit WAL.</li>
<li><strong>Buffer Manager</strong> – <code>TableHeap</code>/<code>BPlusTreeIndex</code> access pages through the shared buffer
pool.</li>
<li><strong>Recovery</strong> – Heap/index mutations generate WAL records (<code>HeapInsert</code>, <code>HeapUpdate</code>,
<code>IndexInsert</code>, …) that ARIES replays.</li>
<li><strong>Background</strong> – MVCC vacuum and index cleanup obtain handles and iterate tuples via
the same abstractions as foreground scans.</li>
</ul>
<hr />
<h2 id="teaching-ideas-7"><a class="header" href="#teaching-ideas-7">Teaching Ideas</a></h2>
<ul>
<li>Implement a toy columnar handle to show how the execution engine can stay agnostic to
storage layout.</li>
<li>Use <code>ScanOptions::projection</code> to push down column pruning into <code>TableIterator</code>.</li>
<li>Enable <code>RUST_LOG=storage::table_heap=trace</code> and trace MVCC version chains as updates
occur.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../storage/disk_io.html">Disk I/O</a>,
<a href="modules/../storage/page_layouts.html">Page &amp; Tuple Layout</a>,
<a href="modules/../storage/table_heap.html">Table Heap &amp; MVCC</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disk-io--scheduler-io_uring-data-pages--wal-runtime"><a class="header" href="#disk-io--scheduler-io_uring-data-pages--wal-runtime">Disk I/O — Scheduler, io_uring Data Pages &amp; WAL Runtime</a></h1>
<h2 id="1-architecture"><a class="header" href="#1-architecture">1. Architecture</a></h2>
<ul>
<li><strong>Request Path</strong>: foreground components enqueue <code>DiskRequest</code> objects via <code>DiskScheduler::{schedule_read, schedule_write, …}</code>. A dispatcher thread drains the global channel and distributes work round-robin to N io_uring workers. Each worker owns its own ring and file-descriptor cache, so once a request is forwarded, execution proceeds entirely off the foreground thread.</li>
<li><strong>Stable APIs</strong>: <code>schedule_read(page_id)</code>, <code>schedule_write(page_id, Bytes)</code>, <code>schedule_read_pages(Vec&lt;PageId&gt;)</code>, <code>schedule_allocate()</code>, <code>schedule_deallocate(page_id)</code> — every call returns a channel the caller can block on or poll.</li>
<li><strong>Batch Reads</strong>: <code>ReadPages</code> fans out per-page SQEs while a shared <code>BatchState</code> tracks completions. Even if the kernel completes I/O out of order, the caller receives a <code>Vec&lt;BytesMut&gt;</code> that preserves the original page order.</li>
</ul>
<h2 id="2-wal-runtime-buffered-io"><a class="header" href="#2-wal-runtime-buffered-io">2. WAL Runtime (buffered I/O)</a></h2>
<ul>
<li>Dedicated WAL runtime threads handle sequential WAL appends/reads using buffered I/O. They now keep a per-thread cache of open segment files, eliminating repeated <code>open()</code>/<code>close()</code> on every log record.</li>
<li>Worker count defaults to <code>max(1, available_parallelism / 2)</code> but is tunable through <code>IOSchedulerConfig</code>.</li>
<li>Optional <code>sync</code> on a request triggers <code>sync_data</code> / <code>fdatasync</code> so <code>WalManager</code> can honour synchronous commit or checkpoint barriers. Data pages stay on the io_uring dataplane; WAL always uses buffered writes.</li>
</ul>
<h2 id="3-io_uring-backend-linux"><a class="header" href="#3-io_uring-backend-linux">3. io_uring Backend (Linux)</a></h2>
<ul>
<li>Each worker owns an <code>IoUring</code> with configurable <code>queue_depth</code>, optional SQPOLL idle timeout, and a pool of registered fixed buffers sized to <code>PAGE_SIZE</code>. Workers submit SQEs asynchronously and drain CQEs in small batches to keep the ring warm.</li>
<li>Read batching relies on shared <code>BatchState</code> instances (<code>Rc&lt;RefCell&lt;_&gt;&gt;</code>) so multi-page callers see ordered results without blocking the kernel on serialization.</li>
<li>Writes keep their payload alive until completion; if a fixed buffer slot is available we reuse it, otherwise we fall back to heap buffers. A companion <code>WriteState</code> tracks an optional <code>fdatasync</code> so the caller still observes exactly one <code>Result&lt;()&gt;</code> once all CQEs land.</li>
<li>Errors (short read/write, errno) are normalised into <code>QuillSQLError</code> values that flow back on the original channel.</li>
</ul>
<h2 id="4-configuration"><a class="header" href="#4-configuration">4. Configuration</a></h2>
<ul>
<li><code>config::IOSchedulerConfig</code> controls:
<ul>
<li><code>workers</code>: number of io_uring workers (default = available parallelism).</li>
<li><code>wal_workers</code>: WAL runtime threads (default workers / 2).</li>
<li><code>iouring_queue_depth</code>, <code>iouring_fixed_buffers</code>, <code>iouring_sqpoll_idle_ms</code>.</li>
<li><code>fsync_on_write</code>: whether data-page writes also issue <code>fdatasync</code> (WAL sync is managed separately by <code>WalManager</code>).</li>
</ul>
</li>
</ul>
<h2 id="5-concurrency--safety"><a class="header" href="#5-concurrency--safety">5. Concurrency &amp; Safety</a></h2>
<ul>
<li>Worker-local file descriptors plus positional I/O remove shared mutable state on the hot path. The new per-worker handle cache further reduces syscall overhead.</li>
<li>Shutdown sequence: enqueue <code>Shutdown</code>, dispatcher forwards it to every worker, each worker drains outstanding SQEs/CQEs, and finally dispatcher + workers are joined.</li>
<li>BufferPool, TableHeap, and the streaming scan ring buffer still integrate via channels; inflight guards prevent duplicate page fetches.</li>
</ul>
<h2 id="6-performance-notes"><a class="header" href="#6-performance-notes">6. Performance Notes</a></h2>
<ul>
<li>Random page access benefits from fewer syscalls and deeper outstanding queue depth than the blocking fallback.</li>
<li>Only the io_uring backend currently ships (Linux x86_64). A portable fallback remains future work.</li>
<li>For large sequential scans, combine <code>ReadPages</code> with the ring-buffer iterator to minimise buffer-pool churn.</li>
</ul>
<h2 id="7-future-work"><a class="header" href="#7-future-work">7. Future Work</a></h2>
<ul>
<li>Queue-depth aware scheduling and CQE bulk harvesting.</li>
<li>Optional group commit (aggregate writes, single fsync) behind configuration.</li>
<li>Metrics hooks (queue depth, submit/complete throughput, latency percentiles, error codes).</li>
<li>Cross-platform fallback backend and richer prioritisation/throttling policies.</li>
<li>Control-plane knobs for throttling individual background workers.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="page-and-tuple-layout"><a class="header" href="#page-and-tuple-layout">Page and Tuple Layout</a></h1>
<h2 id="1-the-page-the-atomic-unit-of-io"><a class="header" href="#1-the-page-the-atomic-unit-of-io">1. The Page: The Atomic Unit of I/O</a></h2>
<p>A database file is not treated as one continuous stream of data. Instead, it is broken down into fixed-size blocks called <strong>pages</strong>. A page is the atomic unit of transfer between the disk and the in-memory <a href="storage/../modules/buffer.html">Buffer Pool</a>. Whenever the database needs to read a piece of data (like a single row), it must load the <em>entire page</em> containing that data into memory.</p>
<p>In QuillSQL, the page size is a constant defined at <code>quill-sql/src/buffer/mod.rs</code>:</p>
<ul>
<li><strong><code>PAGE_SIZE</code></strong>: 4096 bytes (4 KB)</li>
</ul>
<p>This fixed-size approach simplifies buffer management and allows for efficient, aligned I/O operations, especially when using Direct I/O to bypass the OS cache.</p>
<h2 id="2-tablepage-the-slotted-page-layout"><a class="header" href="#2-tablepage-the-slotted-page-layout">2. <code>TablePage</code>: The Slotted Page Layout</a></h2>
<p>While a page is a generic 4KB block of bytes, pages that store actual table data are structured in a specific way. QuillSQL uses a classic <strong>Slotted Page</strong> layout, which is a core concept in database implementation (as taught in CMU 15-445).</p>
<p>A <code>TablePage</code> is organized into three main parts:</p>
<pre><code>&lt;------------------------------ 4KB ------------------------------&gt;
+----------------+-----------------+-----------------+--------------+
|  Page Header   |   Slot Array    |      Free       |   Tuple      |
| (grows -&gt;)     |   (grows -&gt;)    |      Space      |     Data     |
|                |                 |                 | (&lt;- grows)   |
+----------------+-----------------+-----------------+--------------+
</code></pre>
<ol>
<li><strong>Page Header (<code>TablePageHeader</code>)</strong>: Located at the beginning of the page. It contains metadata about the page itself.</li>
<li><strong>Slot Array (<code>tuple_infos</code>)</strong>: An array of <code>TupleInfo</code> structs that grows from after the header. Each entry in this array acts as a "pointer" or "directory entry" for a tuple on the page.</li>
<li><strong>Tuple Data</strong>: The actual raw data of the tuples is stored starting from the <strong>end</strong> of the page, growing backwards towards the middle.</li>
</ol>
<p>This design has a key advantage: <strong>it decouples a tuple's logical identifier from its physical location on the page.</strong></p>
<h3 id="the-recordid-rid"><a class="header" href="#the-recordid-rid">The <code>RecordId</code> (RID)</a></h3>
<p>A specific tuple is uniquely identified by a <code>RecordId</code> (RID). The RID is a stable pointer composed of two parts:</p>
<ul>
<li><strong><code>page_id</code></strong>: The ID of the page where the tuple resides.</li>
<li><strong><code>slot_num</code></strong>: The <strong>index</strong> into the Slot Array on that page.</li>
</ul>
<p>So, <code>RID = (page_id, slot_num)</code>.</p>
<p>When the database needs to delete a tuple or if a variable-length tuple is updated and grows in size, the tuple's data might need to be moved within the page (for compaction). In a slotted page design, we only need to update the <code>offset</code> in the corresponding slot array entry. The tuple's RID (<code>page_id</code>, <code>slot_num</code>) <strong>remains unchanged</strong>. This prevents a cascade of updates to all secondary indexes that might be pointing to that tuple.</p>
<h3 id="tablepageheader-and-slot-tupleinfo"><a class="header" href="#tablepageheader-and-slot-tupleinfo"><code>TablePageHeader</code> and Slot (<code>TupleInfo</code>)</a></h3>
<p>Let's look at the physical layout, as defined in <code>storage/codec/table_page.rs</code>:</p>
<ul>
<li>
<p><strong><code>TablePageHeader</code></strong>:</p>
<ul>
<li><code>lsn</code>: The Log Sequence Number of the last change made to this page, crucial for WAL recovery.</li>
<li><code>next_page_id</code>: The ID of the next page in this table, forming a linked list of pages.</li>
<li><code>num_tuples</code>: The number of active tuples on the page.</li>
<li><code>num_deleted_tuples</code>: The number of "dead" or deleted tuples.</li>
<li><code>tuple_infos</code>: The slot array itself.</li>
</ul>
</li>
<li>
<p><strong><code>TupleInfo</code></strong> (A single slot in the array):</p>
<ul>
<li><code>offset</code>: The byte offset from the beginning of the page where the tuple's data begins.</li>
<li><code>size</code>: The size of the tuple's data in bytes.</li>
<li><code>meta</code>: A nested <code>TupleMeta</code> struct containing critical information for concurrency control.</li>
</ul>
</li>
</ul>
<hr />
<h2 id="for-study--discussion-4"><a class="header" href="#for-study--discussion-4">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Layout Trade-offs</strong>: What is the main benefit of having the tuple data grow from the end of the page backwards, while the header and slot array grow from the beginning forwards? What happens when they meet?</p>
</li>
<li>
<p><strong>Record ID Stability</strong>: Why is it so important that a tuple's <code>RecordId</code> does not change even if the tuple's physical data is moved within the page? What would break if the RID was just a direct byte offset?</p>
</li>
<li>
<p><strong>Large Objects</strong>: The current design assumes a tuple fits entirely on one page. How would you modify this page layout to support tuples that are larger than 4KB (e.g., a long blog post stored in a <code>VARCHAR</code> column)? Research how systems like PostgreSQL handle this with their "TOAST" (The Oversized-Attribute Storage Technique) mechanism.</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Implement a <code>defragment()</code> method for the <code>TablePage</code>. After several insertions and deletions, the free space on a page can become fragmented into small, unusable chunks. This method should reorganize the page by moving the existing tuples to be contiguous, creating a single, large block of free space. Remember to update the <code>offset</code> in each <code>TupleInfo</code> slot after moving its corresponding tuple data!</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-heap-and-mvcc"><a class="header" href="#table-heap-and-mvcc">Table Heap and MVCC</a></h1>
<p>The <code>TableHeap</code> (<code>storage/table_heap.rs</code>) is the component responsible for managing the collection of pages that belong to a single table. While the <code>TablePage</code> defines the <em>layout</em> within a single page, the <code>TableHeap</code> provides the high-level API for inserting, updating, and deleting tuples, making it central to the implementation of MVCC.</p>
<h2 id="tuple-serialization"><a class="header" href="#tuple-serialization"><code>Tuple</code> Serialization</a></h2>
<p>A logical <code>Tuple</code> struct in memory must be converted into a byte array to be stored on a page. This process is handled by <code>storage/codec/tuple.rs</code>.</p>
<p>The serialized format of a tuple consists of two parts:</p>
<ol>
<li><strong>Null Bitmap</strong>: A compact bitmap at the beginning of the tuple data. Each bit corresponds to a column in the schema; if the bit is <code>1</code>, the column's value is <code>NULL</code>. This avoids storing any data for null fields.</li>
<li><strong>Attribute Data</strong>: The actual data for all non-null columns, serialized one after another.</li>
</ol>
<h2 id="tuplemeta-the-heart-of-mvcc"><a class="header" href="#tuplemeta-the-heart-of-mvcc"><code>TupleMeta</code>: The Heart of MVCC</a></h2>
<p>The most important part of a tuple's on-disk metadata is the <code>TupleMeta</code> struct, which is stored directly within the <code>TupleInfo</code> slot in the page header. This is the heart of QuillSQL's <strong>Multi-Version Concurrency Control (MVCC)</strong> implementation.</p>
<ul>
<li><strong><code>insert_txn_id</code></strong>: The ID of the transaction that created this version of the tuple.</li>
<li><strong><code>delete_txn_id</code></strong>: The ID of the transaction that "deleted" this version. (A value of <code>0</code> or <code>INVALID</code> means it's not deleted).</li>
<li><strong><code>is_deleted</code></strong>: A boolean flag indicating the tuple version is considered deleted.</li>
<li><strong><code>prev_version: Option&lt;RecordId&gt;</code></strong>: A link (RID) to the <em>previous</em> version of this logical row.</li>
<li><strong><code>next_version: Option&lt;RecordId&gt;</code></strong>: A link (RID) to the <em>next</em> version of this logical row.</li>
</ul>
<p>These fields allow QuillSQL to maintain a <strong>version chain</strong> for each logical row. When a row is updated, the <code>TableHeap</code>'s <code>mvcc_update</code> method is called, which, instead of overwriting the data, performs the following steps:</p>
<ol>
<li>Creates a new tuple version with the new data by calling <code>insert_tuple</code>.</li>
<li>Sets the <code>prev_version</code> pointer of this new version to the RID of the old version.</li>
<li>Updates the <code>next_version</code> pointer of the old version to point to the new version.</li>
<li>Sets the <code>delete_txn_id</code> on the old version to mark it as "dead".</li>
</ol>
<p>A transaction can then traverse this chain and use the transaction IDs in the <code>TupleMeta</code> to determine which version of a row is visible to it based on its own transaction ID and isolation level, thus achieving transaction isolation without long-held read locks.</p>
<hr />
<h2 id="for-study--discussion-5"><a class="header" href="#for-study--discussion-5">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Version Chain Traversal</strong>: Imagine a transaction with ID <code>T10</code> needs to read a row. It finds a version of the row that was inserted by <code>T5</code> (committed) but deleted by <code>T12</code> (in-progress). Should <code>T10</code> see this version? What if the deleter was <code>T8</code> (committed)? What if the deleter was <code>T10</code> itself? Walk through the visibility check logic.</p>
</li>
<li>
<p><strong>Garbage Collection</strong>: The MVCC model creates many "dead" tuple versions that are no longer visible to any active or future transaction. What is the long-term problem with leaving these dead versions in the database? This problem is typically solved by a process called <strong>vacuuming</strong> or garbage collection. When is it safe to physically remove a dead tuple version?</p>
</li>
<li>
<p><strong>Programming Exercise (Advanced)</strong>: Implement a basic <code>VACUUM</code> function for a <code>TableHeap</code>. This function should scan the table and identify dead tuple versions that are no longer visible to <em>any</em> currently active transaction. Once identified, it should physically remove them from their pages. This is a challenging exercise that touches transaction management, storage, and concurrency.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="buffer-manager"><a class="header" href="#buffer-manager">Buffer Manager</a></h1>
<p>The buffer manager (<code>src/buffer/</code>) implements QuillSQL’s shared buffer pool, bridging the
speed gap between RAM and disk. It lets storage/execution read and write pages safely
while coordinating with WAL and asynchronous I/O.</p>
<hr />
<h2 id="responsibilities-6"><a class="header" href="#responsibilities-6">Responsibilities</a></h2>
<ul>
<li>Maintain a fixed-size set of page frames caching <code>TableHeap</code> and B+Tree pages.</li>
<li>Expose RAII-style guards (pin/unpin) that enforce safe concurrent access.</li>
<li>Keep the page table, replacement policy, dirty-page tracking, and WAL coordination in
sync.</li>
<li>Submit async I/O through <code>DiskScheduler</code>.</li>
</ul>
<hr />
<h2 id="directory-layout-6"><a class="header" href="#directory-layout-6">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>buffer_manager.rs</code></td><td>Core buffer pool.</td><td><code>BufferManager</code>, <code>BufferFrame</code></td></tr>
<tr><td><code>page.rs</code></td><td>Guard types and pin/unpin logic.</td><td><code>ReadPageGuard</code>, <code>WritePageGuard</code></td></tr>
<tr><td><code>replacer.rs</code></td><td>LRU-K + TinyLFU replacement.</td><td><code>Replacer</code></td></tr>
<tr><td><code>metrics.rs</code></td><td>Optional instrumentation hooks.</td><td><code>BufferMetrics</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="key-mechanisms"><a class="header" href="#key-mechanisms">Key Mechanisms</a></h2>
<h3 id="guard-model"><a class="header" href="#guard-model">Guard Model</a></h3>
<ul>
<li><code>ReadPageGuard</code>, <code>WritePageGuard</code>, and <code>UpgradeableGuard</code> ensure only compatible access
modes coexist on a page.</li>
<li>Guards drop automatically to release pins; paired with Rust’s borrow checker, they make
latch semantics tangible.</li>
</ul>
<h3 id="replacement-policy"><a class="header" href="#replacement-policy">Replacement Policy</a></h3>
<ul>
<li><strong>LRU-K</strong> tracks the last K touches to protect hot pages from scan pollution.</li>
<li><strong>TinyLFU</strong> decides whether a new page should enter the cache, offering probabilistic
admission against noisy workloads.</li>
</ul>
<h3 id="wal-coordination"><a class="header" href="#wal-coordination">WAL Coordination</a></h3>
<ul>
<li>Before flushing a dirty page, the buffer checks <code>page_lsn</code> and asks <code>WalManager</code> to
flush up to that LSN (write-ahead rule).</li>
<li><code>set_wal_manager</code> wires the buffer to WAL so checkpoints can inspect the oldest dirty
LSN.</li>
</ul>
<h3 id="disk-scheduler"><a class="header" href="#disk-scheduler">Disk Scheduler</a></h3>
<ul>
<li>All physical reads/writes go through <code>DiskScheduler::submit_*</code>, sharing worker threads
with WAL and demonstrating the benefits of a unified I/O layer.</li>
</ul>
<hr />
<h2 id="interactions-8"><a class="header" href="#interactions-8">Interactions</a></h2>
<ul>
<li><strong>Storage engine</strong> – <code>TableHeap</code> and <code>BPlusTreeIndex</code> access pages exclusively through
the buffer manager.</li>
<li><strong>Recovery</strong> – checkpoints consult the buffer’s dirty page table to build the ARIES DPT.</li>
<li><strong>Background writer</strong> – periodically walks <code>dirty_frames</code> to flush pages in the
background.</li>
</ul>
<hr />
<h2 id="teaching-ideas-8"><a class="header" href="#teaching-ideas-8">Teaching Ideas</a></h2>
<ul>
<li>Disable TinyLFU via feature flag, rerun sqllogictest, and compare hit rates.</li>
<li>Swap the replacement policy with CLOCK to experiment with cache algorithms.</li>
<li>Enable <code>RUST_LOG=buffer=debug</code> and trace the pin/unpin lifecycle of hot pages.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../buffer/page.html">Page &amp; Page Guards</a>,
<a href="modules/../buffer/buffer_pool.html">The Buffer Pool</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="page--page-guards"><a class="header" href="#page--page-guards">Page &amp; Page Guards</a></h1>
<p>Before the Buffer Manager can hand out a reference to a page in memory, it must ensure that the page won't be evicted while it's being used by another thread. This is accomplished by <strong>pinning</strong>.</p>
<h2 id="pinning"><a class="header" href="#pinning">Pinning</a></h2>
<p>Pinning simply means incrementing a "pin count" associated with the page's frame in the buffer pool. A frame with a pin count greater than zero is forbidden from being chosen as a victim by the page replacer.</p>
<ul>
<li>When a thread wants to use a page, it must first pin it.</li>
<li>When the thread is finished with the page, it must <strong>unpin</strong> it (decrementing the count).</li>
</ul>
<p>Manually managing pin counts is tedious and error-prone. Forgetting to unpin a page leads to a memory leak, as the frame can never be evicted. To solve this, QuillSQL uses a common and powerful C++ and Rust pattern: <strong>Resource Acquisition Is Initialization (RAII)</strong>.</p>
<h2 id="readpageguard-and-writepageguard"><a class="header" href="#readpageguard-and-writepageguard"><code>ReadPageGuard</code> and <code>WritePageGuard</code></a></h2>
<p>Instead of returning a raw pointer to the page memory, the <code>BufferManager</code>'s <code>fetch_page_*</code> methods return a <strong>guard</strong> object: <code>ReadPageGuard</code> or <code>WritePageGuard</code>.</p>
<p>These guards are responsible for the lifetime of the pin and the lock on the page:</p>
<ol>
<li>
<p><strong>Acquisition</strong>: When a <code>PageGuard</code> is created, its constructor acquires the appropriate lock (<code>RwLock</code>) on the page's frame and increments the frame's pin count.</p>
<ul>
<li><code>ReadPageGuard</code> takes a read lock, allowing multiple concurrent readers.</li>
<li><code>WritePageGuard</code> takes an exclusive write lock.</li>
</ul>
</li>
<li>
<p><strong>Usage</strong>: The calling code uses the guard object to access the page's data. The guard provides safe, locked access to the underlying byte array.</p>
</li>
<li>
<p><strong>Release</strong>: When the guard variable goes out of scope (e.g., at the end of a function), its <code>drop()</code> method is automatically called by the Rust compiler. This <code>drop()</code> implementation handles all the cleanup:</p>
<ul>
<li>It decrements the pin count.</li>
<li>It releases the lock on the frame.</li>
<li>If it's a <code>WritePageGuard</code> and the data was modified, it informs the <code>BufferManager</code> that the page is now <strong>dirty</strong>.</li>
</ul>
</li>
</ol>
<p>This RAII pattern makes using the buffer pool much safer and more ergonomic, as it makes it impossible to forget to unpin a page or release a lock.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-buffer-pool-architecture-and-lifecycle"><a class="header" href="#the-buffer-pool-architecture-and-lifecycle">The Buffer Pool: Architecture and Lifecycle</a></h1>
<h2 id="1-core-components--architecture"><a class="header" href="#1-core-components--architecture">1. Core Components &amp; Architecture</a></h2>
<p>QuillSQL's buffer management is split into two main structs, reflecting a separation of concerns:</p>
<ul>
<li><strong><code>BufferPool</code> (<code>buffer/buffer_pool.rs</code>)</strong>: A low-level, "dumb" container. It owns the actual memory arena for pages and provides basic mapping from a <code>PageId</code> to a memory location (<code>FrameId</code>).</li>
<li><strong><code>BufferManager</code> (<code>buffer/buffer_manager.rs</code>)</strong>: The high-level, "smart" coordinator. It contains the <code>BufferPool</code> and implements all the logic for fetching pages, choosing which pages to evict, and interacting with other database components like the transaction and recovery managers.</li>
</ul>
<p>This architecture is centered around three key data structures:</p>
<ol>
<li>
<p><strong>Frames (The Arena)</strong>: The <code>BufferPool</code> pre-allocates a large, contiguous block of memory on the heap. This block is divided into a fixed number of smaller chunks called <strong>frames</strong>. Each frame is exactly <code>PAGE_SIZE</code> (4KB) and can hold the contents of one disk page.</p>
</li>
<li>
<p><strong>Page Table (<code>page_table</code>)</strong>: A hash map (specifically, a concurrent <code>DashMap</code>) that maps a logical <code>PageId</code> to the <code>FrameId</code> where it currently resides in memory. This provides fast O(1) lookups to check if a page is already in the buffer pool.</p>
</li>
<li>
<p><strong>Replacer (<code>LRUKReplacer</code>)</strong>: When a requested page is not in memory and the buffer pool is full, one of the existing pages must be <strong>evicted</strong> to make room. The <code>Replacer</code> is the component that implements the page replacement policy and decides which page is the best candidate for eviction. QuillSQL uses an <strong>LRU-K</strong> replacement policy, a sophisticated variant of the classic Least Recently Used (LRU) algorithm.</p>
</li>
</ol>
<h2 id="2-the-lifecycle-of-a-page-request"><a class="header" href="#2-the-lifecycle-of-a-page-request">2. The Lifecycle of a Page Request</a></h2>
<p>When another part of the database (e.g., the execution engine) needs to access a page, it calls <code>buffer_manager.fetch_page_read(page_id)</code> or <code>fetch_page_write(page_id)</code>. This initiates a critical sequence of events.</p>
<p>The flow is as follows:</p>
<ol>
<li>
<p><strong>Request</strong>: An executor requests Page <code>P</code>.</p>
</li>
<li>
<p><strong>Lookup</strong>: The <code>BufferManager</code> consults the <code>PageTable</code>.</p>
</li>
<li>
<p><strong>Case 1: Cache Hit</strong></p>
<ul>
<li>The <code>PageTable</code> contains an entry for <code>P</code>, mapping it to <code>FrameId</code> <code>F</code>.</li>
<li>The <code>BufferManager</code> increments the pin count for frame <code>F</code>.</li>
<li>It informs the <code>LRUKReplacer</code> that the page has been accessed (updating its priority).</li>
<li>It returns a <code>PageGuard</code> wrapping a reference to the memory in frame <code>F</code>.</li>
</ul>
</li>
<li>
<p><strong>Case 2: Cache Miss</strong></p>
<ul>
<li>The <code>PageTable</code> has no entry for <code>P</code>.</li>
<li>The <code>BufferManager</code> must bring the page from disk. It asks the <code>Replacer</code> to choose a <strong>victim frame</strong> <code>F_v</code> to evict.</li>
<li><strong>If the victim frame <code>F_v</code> is dirty</strong>: The <code>BufferManager</code> first writes the contents of <code>F_v</code> back to disk via the <code>DiskScheduler</code>. This is essential for data durability.</li>
<li>The <code>PageTable</code> entry for the old page residing in <code>F_v</code> is removed.</li>
<li>The <code>BufferManager</code> issues a read request to the <code>DiskScheduler</code> to load page <code>P</code>'s data from disk into frame <code>F_v</code>.</li>
<li>The <code>PageTable</code> is updated with the new mapping: <code>P -&gt; F_v</code>.</li>
<li>The process then continues like a cache hit: frame <code>F_v</code> is pinned and a <code>PageGuard</code> is returned.</li>
</ul>
</li>
</ol>
<h2 id="3-concurrency"><a class="header" href="#3-concurrency">3. Concurrency</a></h2>
<p>The buffer pool is a shared resource accessed by many concurrent threads. QuillSQL uses a combination of locking strategies:</p>
<ul>
<li><strong>Page Table</strong>: A <code>DashMap</code> is used for the page table, which is highly optimized for concurrent reads and writes.</li>
<li><strong>Frame-Level Locks</strong>: Each frame in the pool has its own <code>RwLock</code>. A <code>ReadPageGuard</code> acquires a read lock on the frame, allowing multiple threads to read the same page concurrently. A <code>WritePageGuard</code> acquires an exclusive write lock, ensuring that only one thread can modify a page at a time.</li>
<li><strong>Replacer/Free List</strong>: These shared structures are protected by a <code>Mutex</code>.</li>
</ul>
<h2 id="4-integration-with-wal-and-recovery"><a class="header" href="#4-integration-with-wal-and-recovery">4. Integration with WAL and Recovery</a></h2>
<p>The Buffer Manager is a key player in the ARIES recovery protocol.</p>
<ul>
<li><strong>Dirty Pages</strong>: When a <code>WritePageGuard</code> is dropped, if it has modified the page, it marks the page as <strong>dirty</strong>. The <code>BufferManager</code> maintains a <code>dirty_page_table</code> that tracks all dirty pages and the Log Sequence Number (LSN) of the first WAL record that caused the page to become dirty.</li>
<li><strong>Forced WAL (Write-Ahead Logging)</strong>: Before a dirty page can be written back to disk (either during eviction or a checkpoint), the <code>BufferManager</code> must ensure that all WAL records up to that page's current LSN have been flushed to durable storage. This is the fundamental <strong>WAL rule</strong> and is enforced by the <code>flush_page</code> method, which calls <code>wal_manager.flush(lsn)</code> before writing the page to disk.</li>
</ul>
<hr />
<h2 id="for-study--discussion-6"><a class="header" href="#for-study--discussion-6">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Replacement Policies</strong>: QuillSQL uses LRU-K. What are the potential advantages of LRU-K over a simple LRU policy? What kind of workload would benefit most? Conversely, what are the trade-offs of using Clock/Second-Chance instead?</p>
</li>
<li>
<p><strong>The "Double Caching" Problem</strong>: We mentioned that using Direct I/O helps avoid double caching. If Direct I/O is disabled, how does the database's buffer pool interact with the operating system's file system cache? Why can this lead to suboptimal performance?</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Implement a <code>ClockReplacer</code> that adheres to the <code>Replacer</code> trait. Modify the <code>BufferManager</code> to use your new replacer instead of <code>LRUKReplacer</code>. Run the benchmark suite and compare the performance. Does it change?</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Add metrics to the <code>BufferManager</code> to track the buffer pool hit rate (i.e., <code>num_hits / (num_hits + num_misses)</code>). You could expose this via a new <code>SHOW BUFFER_STATS;</code> SQL command.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="index-module"><a class="header" href="#index-module">Index Module</a></h1>
<p>Indexes live in <code>src/storage/index/</code>. QuillSQL currently ships a B+Tree (B-link variant)
that is exposed to execution via <code>IndexHandle</code>. Indexes allow point lookups and range
scans in O(log n), dramatically reducing the need for full table scans.</p>
<hr />
<h2 id="responsibilities-7"><a class="header" href="#responsibilities-7">Responsibilities</a></h2>
<ul>
<li>Maintain an ordered key → <code>RecordId</code> mapping per indexed table.</li>
<li>Support point probes, range scans, insert/update/delete maintenance.</li>
<li>Cooperate with MVCC: entries reference heap tuples while visibility checks remain in
execution/transaction code.</li>
<li>Provide <code>IndexHandle::range_scan</code>, returning a <code>TupleStream</code> so physical operators don’t
need to know tree internals.</li>
</ul>
<hr />
<h2 id="directory-layout-7"><a class="header" href="#directory-layout-7">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Purpose</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>btree_index.rs</code></td><td>Core B+Tree, page formats, insert/delete logic.</td><td><code>BPlusTreeIndex</code></td></tr>
<tr><td><code>btree_iterator.rs</code></td><td>Range-scan iterator with sibling traversal.</td><td><code>TreeIndexIterator</code></td></tr>
<tr><td><code>btree_codec.rs</code></td><td>Page encode/decode utilities.</td><td><code>BPlusTreeLeafPageCodec</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="b-link-structure"><a class="header" href="#b-link-structure">B-link Structure</a></h3>
<p>Each leaf stores a pointer to its right sibling. Iterators use this to keep scanning even
if a concurrent split occurs, avoiding restarts from the root and enabling latch-free
range scans.</p>
<h3 id="latch-crabbing"><a class="header" href="#latch-crabbing">Latch Crabbing</a></h3>
<p>Insert/delete operations climb the tree with shared latches and upgrade only when
necessary (e.g., right before splitting), reducing contention.</p>
<h3 id="range-scan--tuplestream"><a class="header" href="#range-scan--tuplestream">Range Scan → TupleStream</a></h3>
<p><code>IndexHandle::range_scan</code> wraps <code>TreeIndexIterator</code> and automatically fetches heap tuples,
returning <code>(rid, meta, tuple)</code> triples. Execution remains storage-agnostic.</p>
<h3 id="garbage-signals"><a class="header" href="#garbage-signals">Garbage Signals</a></h3>
<p><code>BPlusTreeIndex::note_potential_garbage</code> counts invisible keys; background index vacuum
consults the counter plus <code>IndexVacuumConfig</code> before pruning.</p>
<hr />
<h2 id="interactions-9"><a class="header" href="#interactions-9">Interactions</a></h2>
<ul>
<li><strong>Catalog</strong> – <code>Catalog::create_index</code> registers the index with <code>IndexRegistry</code>; execution
fetches <code>Arc&lt;dyn IndexHandle&gt;</code> via the registry.</li>
<li><strong>Execution</strong> – <code>PhysicalIndexScan</code> uses <code>ExecutionContext::index_stream</code>; DML operators
call <code>insert_tuple_with_indexes</code> so heap writes and index maintenance stay in sync.</li>
<li><strong>Transaction/MVCC</strong> – heaps store transaction metadata; indexes just reference RIDs, so
MVCC visibility is enforced when tuples are materialised.</li>
<li><strong>Recovery</strong> – WAL contains <code>IndexInsert/IndexDelete</code> records to replay structural
changes after crashes.</li>
</ul>
<hr />
<h2 id="teaching-ideas-9"><a class="header" href="#teaching-ideas-9">Teaching Ideas</a></h2>
<ul>
<li>Build a covering index example to show how avoiding heap lookups improves latency.</li>
<li>Instrument <code>TreeIndexIterator</code> to visualise sibling traversal during range scans.</li>
<li>Compare SeqScan vs IndexScan on selective predicates to highlight indexing benefits.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../index/btree_index.html">B+Tree internals</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="b-tree-index--architecture-and-concurrency"><a class="header" href="#b-tree-index--architecture-and-concurrency">B+ Tree Index — Architecture and Concurrency</a></h1>
<h2 id="1-architecture-overview"><a class="header" href="#1-architecture-overview">1. Architecture Overview</a></h2>
<h3 id="11-node-and-page-structure"><a class="header" href="#11-node-and-page-structure">1.1 Node and Page Structure</a></h3>
<ul>
<li><strong>Node Types</strong>: <code>Internal</code> and <code>Leaf</code>.
<ul>
<li><strong>Internal Nodes</strong>: Store separator keys and pointers to child pages. The first pointer is a "sentinel" that points to the subtree for all keys less than the first key in the node.</li>
<li><strong>Leaf Nodes</strong>: Store <code>(key, RecordId)</code> pairs in sorted order. Leaves are linked together in a singly linked list (<code>next_page_id</code>) to allow for efficient range scans.</li>
</ul>
</li>
<li><strong>Header Page</strong>: A fixed page (<code>header_page_id</code>) that acts as the entry point to the tree. It stores the <code>root_page_id</code>, allowing for atomic updates to the tree root when it splits or shrinks.</li>
<li><strong>Page Layout</strong>:
<ul>
<li><strong>Internal Page</strong>: <code>{Header, High Key, Array&lt;(Key, ChildPageId)&gt;}</code>. The <code>High Key</code> is part of the B-link optimization.</li>
<li><strong>Leaf Page</strong>: <code>{Header, Array&lt;(Key, RID)&gt;}</code>.</li>
</ul>
</li>
</ul>
<h3 id="12-b-link-structure"><a class="header" href="#12-b-link-structure">1.2 B-link Structure</a></h3>
<p>The tree uses B-link pointers (<code>next_page_id</code>) on all levels (both internal and leaf nodes). This creates a "side-link" to the right sibling. This is crucial for concurrency, as it allows readers to recover from transient inconsistent states caused by concurrent page splits by "chasing" the link to the right sibling.</p>
<pre><code>              +------------------+
              |   Root (Int)     |
              +------------------+
             /         |         \
   +--------+      +--------+      +--------+
   | Int P1 |-----&gt;| Int P2 |-----&gt;| Int P3 |  (Internal B-link pointers)
   +--------+      +--------+      +--------+
   /   |   \      /   |   \      /   |   \
+----+ +----+  +----+ +----+  +----+ +----+
| L1 |-| L2 |-&gt;| L3 |-| L4 |-&gt;| L5 |-| L6 | (Leaf chain / B-links)
+----+ +----+  +----+ +----+  +----+ +----+
</code></pre>
<h2 id="2-concurrency-control"><a class="header" href="#2-concurrency-control">2. Concurrency Control</a></h2>
<p>The B+Tree employs a sophisticated, lock-free read path and a high-concurrency write path using latch crabbing.</p>
<h3 id="21-read-path-optimistic-lock-coupling-olc-with-b-links"><a class="header" href="#21-read-path-optimistic-lock-coupling-olc-with-b-links">2.1 Read Path: Optimistic Lock Coupling (OLC) with B-links</a></h3>
<ul>
<li>Readers traverse the tree from the root without taking any locks.</li>
<li>On each page, a <code>version</code> number is read before and after processing the page's contents. If the version changes, it indicates a concurrent modification, and the read operation restarts from the root.</li>
<li>If a reader is traversing an internal node and the search key is greater than or equal to the node's <code>high_key</code>, it knows a split has occurred. Instead of restarting, it can use the <code>next_page_id</code> B-link to "chase" to the right sibling and continue the search, minimizing restarts.</li>
</ul>
<h3 id="22-write-path-latch-crabbing"><a class="header" href="#22-write-path-latch-crabbing">2.2 Write Path: Latch Crabbing</a></h3>
<p>Writers (insert/delete) use a technique called <strong>latch crabbing</strong> (or lock coupling) to ensure safe concurrent modifications.</p>
<ul>
<li><strong>Process</strong>: A writer acquires a write latch on a parent node before fetching and latching a child node. Once the child is latched, the writer checks if the child is "safe" for the operation (i.e., not full for an insert, not at minimum size for a delete).
<ul>
<li>If the child is <strong>safe</strong>, the latch on the parent (and all other ancestors) is released.</li>
<li>If the child is <strong>unsafe</strong>, the parent latch is held, as the child might need to split or merge, which would require modifying the parent.</li>
</ul>
</li>
<li><strong><code>Context</code> Struct</strong>: This process is managed by a <code>Context</code> struct that holds the stack of write guards (<code>write_set</code>) for the current traversal path. Releasing ancestor latches is as simple as clearing this stack.</li>
</ul>
<pre><code>Latch Crabbing on Insert:
1. Latch(Root)
2. Descend to Child C1. Latch(C1).
3. Check if C1 is safe (not full).
   IF SAFE:
     ReleaseLatch(Root). Path is now just {C1}.
   IF UNSAFE (full):
     Keep Latch(Root). Path is {Root, C1}.
4. Descend from C1 to C2. Latch(C2).
5. Check if C2 is safe... and so on.
</code></pre>
<h3 id="23-deadlock-avoidance"><a class="header" href="#23-deadlock-avoidance">2.3 Deadlock Avoidance</a></h3>
<p>When modifying siblings (during merge or redistribution), deadlocks are possible if two threads try to acquire latches on the same two pages in opposite orders. This is prevented by enforcing a strict <strong>PageId-ordered locking</strong> protocol. When two sibling pages must be latched, the page with the lower <code>PageId</code> is always latched first.</p>
<h2 id="3-key-algorithms--features"><a class="header" href="#3-key-algorithms--features">3. Key Algorithms &amp; Features</a></h2>
<ul>
<li><strong>Parent-Guided Redirection</strong>: During an insert or delete, after a writer has descended to a leaf, it re-validates its position using the parent (if a latch is still held). If a concurrent split has moved the target key range to a different sibling, the writer can jump directly to the correct page instead of traversing the leaf chain, preventing race conditions.</li>
<li><strong>Iterator</strong>: The iterator performs a forward scan by following the leaf chain (<code>next_page_id</code>). It uses a lightweight form of OLC, checking the leaf page version to detect concurrent modifications and restart if necessary to ensure it doesn't miss keys.
<ul>
<li>Sequential Scan Optimization (RingBuffer): For large range scans, the iterator switches to a "synchronous batch fetch + local ring buffer" mode. It fills a small <code>RingBuffer&lt;BytesMut&gt;</code> with consecutive leaf pages (by following <code>next_page_id</code>) and then decodes KVs locally without holding page guards for long. This reduces buffer pool pollution and syscall/lock overhead.</li>
<li>Two Iteration Modes:
<ul>
<li>Guard Mode: Keep a <code>ReadPageGuard</code> and decode per step; prefetch next leaf best-effort.</li>
<li>Bytes Mode: After switching, decode from <code>BytesMut</code> buffers in the local ring; when a leaf is exhausted, pop next bytes from the ring or refill by following the chain.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Prefix Compression</strong>: Keys in internal nodes are prefix-compressed to save space. Each key is stored as <code>(lcp, suffix_len, suffix)</code>. This reduces the size of internal pages, increasing the tree's fanout and reducing its height, which improves cache performance and reduces I/O.</li>
<li><strong>Split/Merge Safety</strong>:
<ul>
<li><strong>Split</strong>: When a node splits, the new right sibling is written first. Then, the B-link pointer and separator key are published atomically by updating the left sibling and parent. This ensures readers can always navigate the structure correctly.</li>
<li><strong>Merge/Redistribute</strong>: When a node is underfull, the implementation first tries to borrow an entry from a sibling (redistribute). If both siblings are at minimum size, it merges with a sibling. All these operations carefully maintain the B-link chain and parent pointers.</li>
</ul>
</li>
</ul>
<h2 id="4-benchmarks--performance"><a class="header" href="#4-benchmarks--performance">4. Benchmarks &amp; Performance</a></h2>
<h3 id="41-example-range-scan-benchmark"><a class="header" href="#41-example-range-scan-benchmark">4.1 Example: Range Scan Benchmark</a></h3>
<p>This benchmark measures the efficiency of the leaf-chain traversal, which is critical for <code>SELECT</code> queries with <code>WHERE</code> clauses on indexed columns. It benefits from iterator prefetching and prefix compression.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pseudo-code for a range scan benchmark
use std::time::Instant;

fn benchmark_range_scan(index: Arc&lt;BPlusTreeIndex&gt;, num_keys: i64, num_passes: usize) {
    // 1. Populate the index with sequential keys
    for key in 1..=num_keys {
        let tuple = create_tuple_from_key(key, index.key_schema.clone());
        index.insert(&amp;tuple, create_rid_from_key(key)).unwrap();
    }

    // 2. Run the benchmark
    let start = Instant::now();
    let mut count = 0;
    for _ in 0..num_passes {
        // Create an iterator over the full key range
        let mut iter = TreeIndexIterator::new(index.clone(), ..);
        while let Some(_) = iter.next().unwrap() {
            count += 1;
        }
    }
    let elapsed = start.elapsed();
    let total_items_scanned = num_keys as usize * num_passes;
    let items_per_sec = total_items_scanned as f64 / elapsed.as_secs_f64();

    println!(
        "Range Scan: Scanned {} items in {:?}. Throughput: {:.2} items/sec",
        total_items_scanned, elapsed, items_per_sec
    );
}
<span class="boring">}</span></code></pre></pre>
<h3 id="42-performance-notes"><a class="header" href="#42-performance-notes">4.2 Performance Notes</a></h3>
<ul>
<li><strong>Hot Reads</strong>: Performance on hot-spot reads depends on keeping upper levels and hot leaves resident in the buffer pool. Warm up the cache for read-heavy benchmarks. Protect hot pages from pollution by enabling TinyLFU admission.</li>
<li><strong>Large Range Scans</strong>: Prefer table SeqScan with ring buffer (bypass) when scanning most of the table. For index scans over very large ranges, consider future Bitmap Heap Scan rather than bypassing the pool for leaves.</li>
</ul>
<h3 id="43-configuration"><a class="header" href="#43-configuration">4.3 Configuration</a></h3>
<ul>
<li><code>config::BTreeConfig</code> controls iterator behavior:
<ul>
<li><code>seq_batch_enable</code> (bool): enable batch mode with local ring buffer.</li>
<li><code>seq_window</code> (usize): number of leaf pages to prefill into the ring per refill.</li>
<li><code>prefetch_enable</code>/<code>prefetch_window</code>: guard-mode prefetch hints to buffer pool.
Defaults are conservative; increase <code>seq_window</code> for long scans to reduce I/O hop.</li>
</ul>
</li>
</ul>
<h2 id="5-future-work"><a class="header" href="#5-future-work">5. Future Work</a></h2>
<ul>
<li>Stronger OLC with bounded retries and telemetry.</li>
<li>CSB+-like internal layout and columnar key prefixing.</li>
<li>NUMA-aware partitioning and router.</li>
<li>WAL/MVCC for crash recovery and snapshot isolation.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recovery--wal-module"><a class="header" href="#recovery--wal-module">Recovery / WAL Module</a></h1>
<p><code>src/recovery/</code> guarantees the Durability part of ACID. Through WAL, checkpoints, and the
ARIES algorithm, QuillSQL can recover to a consistent state after crashes.</p>
<hr />
<h2 id="responsibilities-8"><a class="header" href="#responsibilities-8">Responsibilities</a></h2>
<ul>
<li>Generate WAL records for every change and assign monotonically increasing LSNs.</li>
<li>Manage WAL buffers, synchronous flushes, and the optional background WAL writer.</li>
<li>Run the ARIES Analysis → Redo → Undo sequence during startup.</li>
<li>Maintain the control file so the latest checkpoint and log truncation point are known.</li>
</ul>
<hr />
<h2 id="directory-layout-8"><a class="header" href="#directory-layout-8">Directory Layout</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Path</th><th>Description</th><th>Key Types</th></tr></thead><tbody>
<tr><td><code>wal_manager.rs</code></td><td>Log writer, buffer manager, background thread spawner.</td><td><code>WalManager</code>, <code>WalWriterHandle</code></td></tr>
<tr><td><code>wal_record.rs</code></td><td>All record variants.</td><td><code>WalRecord</code>, <code>LogSequenceNumber</code></td></tr>
<tr><td><code>recovery_manager.rs</code></td><td>ARIES driver.</td><td><code>RecoveryManager</code>, <code>RecoverySummary</code></td></tr>
<tr><td><code>control_file.rs</code></td><td>Persistent metadata (checkpoint info).</td><td><code>ControlFileManager</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="wal-highlights"><a class="header" href="#wal-highlights">WAL Highlights</a></h2>
<ul>
<li><strong>Write-ahead rule</strong> – before flushing a dirty page, ensure <code>page_lsn &lt;= flushed_lsn</code>
via <code>WalManager::flush_until</code>.</li>
<li><strong>Record types</strong> – logical (<code>HeapInsert</code>, <code>IndexDelete</code>) for redo/undo and physical
(<code>PageWrite</code>, <code>PageDelta</code>) for large changes.</li>
<li><strong>Segmentation</strong> – WAL files are cut into segments per <code>WalOptions::segment_size</code>, and
background writers can flush them asynchronously.</li>
</ul>
<hr />
<h2 id="aries-recovery"><a class="header" href="#aries-recovery">ARIES Recovery</a></h2>
<ol>
<li><strong>Analysis</strong> – read the latest checkpoint, rebuild the Dirty Page Table (DPT) and
Active Transaction Table (ATT).</li>
<li><strong>Redo</strong> – scan forward from the checkpoint LSN, reapplying operations when the DPT
indicates a page may be out of date.</li>
<li><strong>Undo</strong> – roll back transactions still in ATT, writing Compensation Log Records (CLR)
so the process is idempotent even if another crash happens mid-undo.</li>
</ol>
<p><code>RecoverySummary</code> reports how many records were redone and which transactions require
manual attention—great for classroom demonstrations.</p>
<hr />
<h2 id="interactions-10"><a class="header" href="#interactions-10">Interactions</a></h2>
<ul>
<li><strong>TransactionManager</strong> – emits <code>Begin</code>, <code>Commit</code>, <code>Abort</code> records and supplies undo
information.</li>
<li><strong>BufferManager</strong> – links to WAL via <code>set_wal_manager</code>; checkpoints rely on the buffer’s
dirty page metadata.</li>
<li><strong>Background workers</strong> – WAL writer and checkpoint worker live in <code>background</code> and use
handles exposed by <code>WalManager</code>.</li>
</ul>
<hr />
<h2 id="teaching-ideas-10"><a class="header" href="#teaching-ideas-10">Teaching Ideas</a></h2>
<ul>
<li>Simulate crashes (e.g., panic right after <code>wal_manager.flush(None)</code>) and inspect log
output on restart.</li>
<li>Add a new WAL record type (like <code>CreateIndex</code>) to see how <code>RecoveryManager</code> must be
extended.</li>
<li>Compare physical vs logical redo costs to discuss ARIES trade-offs.</li>
</ul>
<hr />
<p>Further reading: <a href="modules/../recovery/aries.html">ARIES details</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-aries-recovery-protocol"><a class="header" href="#the-aries-recovery-protocol">The ARIES Recovery Protocol</a></h1>
<p>Of the four ACID properties, <strong>Durability</strong> is the one that guarantees that once a transaction is committed, its changes will survive any subsequent system failure. In a disk-based database, this is achieved through a careful and robust recovery protocol. QuillSQL implements a recovery strategy inspired by the well-known <strong>ARIES</strong> (Algorithm for Recovery and Isolation Exploiting Semantics) protocol, centered around a <strong>Write-Ahead Log (WAL)</strong>.</p>
<h2 id="1-the-write-ahead-logging-wal-principle"><a class="header" href="#1-the-write-ahead-logging-wal-principle">1. The Write-Ahead Logging (WAL) Principle</a></h2>
<p>The fundamental rule of WAL is simple but powerful:</p>
<blockquote>
<p><strong>Before a modified data page is ever written from memory back to disk, the log record describing that modification must first be written to durable storage (the log file).</strong></p>
</blockquote>
<p>This allows the database to perform most of its data modifications in memory on the <a href="recovery/../modules/buffer.html">Buffer Pool</a> without needing to synchronously write every changed page to disk, which would be extremely slow. In case of a crash, the database can use the log to reconstruct the state of the system and ensure all committed changes are present and all uncommitted changes are undone.</p>
<h3 id="log-records-walrecord"><a class="header" href="#log-records-walrecord">Log Records (<code>WalRecord</code>)</a></h3>
<p>The WAL is a sequential, append-only file composed of <strong>log records</strong>. Each record is assigned a unique, monotonically increasing <strong>Log Sequence Number (LSN)</strong>. A log record in QuillSQL (<code>src/recovery/wal_record.rs</code>) generally contains:</p>
<ul>
<li><strong>LSN</strong>: The address of the log record.</li>
<li><strong>Transaction ID</strong>: The ID of the transaction that generated this record.</li>
<li><strong>Payload</strong>: The actual content of the log record, which varies by type.</li>
</ul>
<p>QuillSQL uses several types of log records:</p>
<ul>
<li><strong><code>Transaction</code></strong>: Marks the <code>BEGIN</code>, <code>COMMIT</code>, or <code>ABORT</code> of a transaction.</li>
<li><strong><code>PageWrite</code> / <code>PageDelta</code></strong>: Physical/Physiological records describing a change to a page. <code>PageWrite</code> contains a full image of the page (used for the first write after a checkpoint, a technique called First-Page-Write or FPW), while <code>PageDelta</code> contains only the changed bytes.</li>
<li><strong><code>HeapInsert</code> / <code>HeapUpdate</code> / <code>HeapDelete</code></strong>: Logical records describing a high-level heap operation. These are primarily used for generating precise undo operations.</li>
<li><strong><code>Checkpoint</code></strong>: A special record that marks a point of partial durability, allowing the log to be truncated.</li>
<li><strong><code>CLR</code> (Compensation Log Record)</strong>: A special record written during recovery to describe an <strong>undo</strong> action. CLRs are redo-only and are never undone themselves.</li>
</ul>
<h2 id="2-the-aries-recovery-protocol"><a class="header" href="#2-the-aries-recovery-protocol">2. The ARIES Recovery Protocol</a></h2>
<p>On database startup, the <code>RecoveryManager</code> (<code>recovery/recovery_manager.rs</code>) is invoked to <code>replay()</code> the WAL. This process follows the three phases of ARIES.</p>
<h3 id="phase-1-analysis"><a class="header" href="#phase-1-analysis">Phase 1: Analysis</a></h3>
<p>The goal of the Analysis phase (<code>recovery/analysis.rs</code>) is to figure out the state of the database at the exact moment of the crash.</p>
<ol>
<li>It starts by finding the last successful <code>Checkpoint</code> record in the WAL.</li>
<li>It then scans the log <strong>forward</strong> from that checkpoint to the end of the log.</li>
<li>During this scan, it builds two critical data structures:
<ul>
<li><strong>Active Transaction Table (ATT)</strong>: A list of all transactions that have a <code>BEGIN</code> record but no corresponding <code>COMMIT</code> or <code>ABORT</code> record. These are the potential "loser" transactions that will need to be undone.</li>
<li><strong>Dirty Page Table (DPT)</strong>: A list of all pages that were modified in the buffer pool but might not have been written to disk before the crash. For each dirty page, it records the LSN of the <em>first</em> log record that made it dirty (this is called the <code>recLSN</code>).</li>
</ul>
</li>
</ol>
<p>At the end of this phase, the <code>RecoveryManager</code> knows exactly which transactions to roll back and the earliest point in the log from which it needs to start re-applying changes.</p>
<h3 id="phase-2-redo-repeating-history"><a class="header" href="#phase-2-redo-repeating-history">Phase 2: Redo (Repeating History)</a></h3>
<p>The goal of the Redo phase (<code>recovery/redo.rs</code>) is to restore the database to its exact state at the moment of the crash, including all changes from both committed and uncommitted (loser) transactions.</p>
<ol>
<li>The Redo phase finds the smallest <code>recLSN</code> from the Dirty Page Table built during Analysis. This LSN is the starting point for the redo scan.</li>
<li>It scans the log <strong>forward</strong> from this starting point.</li>
<li>For every log record it encounters that describes a physical change to a page (e.g., <code>PageWrite</code>, <code>PageDelta</code>, <code>Heap*</code>), it re-applies the change. This is idempotent: if the change is already present on the page (because it was successfully flushed to disk before the crash), re-applying it does no harm.</li>
</ol>
<p>At the end of this phase, the database state on disk is identical to how it was in memory right before the crash.</p>
<h3 id="phase-3-undo-rolling-back-losers"><a class="header" href="#phase-3-undo-rolling-back-losers">Phase 3: Undo (Rolling Back Losers)</a></h3>
<p>The final phase (<code>recovery/undo.rs</code>) is responsible for rolling back all the "loser" transactions identified during Analysis.</p>
<ol>
<li>The <code>UndoExecutor</code> takes the list of loser transactions.</li>
<li>For each loser transaction, it scans the WAL <strong>backwards</strong>, following the chain of log records for that transaction.</li>
<li>For each operation record (like <code>HeapInsert</code>, <code>HeapUpdate</code>), it performs the logical inverse operation:
<ul>
<li>To undo an <code>Insert</code>, it performs a <code>Delete</code>.</li>
<li>To undo a <code>Delete</code>, it restores the deleted data.</li>
<li>To undo an <code>Update</code>, it restores the data from before the update.</li>
</ul>
</li>
<li><strong>Crucially</strong>, for every undo action it performs, it writes a <strong>Compensation Log Record (CLR)</strong> to the WAL. The CLR contains information about the undo action and, importantly, a pointer to the <em>next</em> log record that needs to be undone for that transaction.</li>
</ol>
<p>This use of CLRs makes the recovery process itself crash-proof. If the system crashes <em>during the undo phase</em>, the next time recovery runs, it will see the CLRs. It will simply continue the undo process from where it left off by following the pointers in the CLRs, without ever having to undo an undo action.</p>
<h2 id="3-checkpoints"><a class="header" href="#3-checkpoints">3. Checkpoints</a></h2>
<p>If the log were allowed to grow forever, recovery would become slower and slower. <strong>Checkpoints</strong> are a background process that periodically creates a point of partial durability.</p>
<p>A checkpoint does the following:</p>
<ol>
<li>Temporarily stops new transactions from starting.</li>
<li>Writes a <code>BEGIN_CHECKPOINT</code> record to the WAL, containing the current ATT and DPT.</li>
<li>Flushes all dirty pages from the buffer pool to disk.</li>
<li>Writes an <code>END_CHECKPOINT</code> record to the WAL.</li>
</ol>
<p>Once a checkpoint is complete, the <code>RecoveryManager</code> knows that all changes described in log records before the <code>BEGIN_CHECKPOINT</code> record are safely on disk. Therefore, those older parts of the WAL file are no longer needed for recovery and can be truncated or recycled, keeping the recovery process efficient.</p>
<hr />
<h2 id="for-study--discussion-7"><a class="header" href="#for-study--discussion-7">For Study &amp; Discussion</a></h2>
<ol>
<li>
<p><strong>Repeating History</strong>: The Redo phase re-applies changes from <em>all</em> transactions, including those that will be undone later (the "losers"). This seems wasteful. Why is this "repeating history" approach a core principle of ARIES? What would go wrong if we tried to only redo changes from committed transactions?</p>
</li>
<li>
<p><strong>Compensation Log Records (CLRs)</strong>: What specific problem would occur if the system crashed during the Undo phase and we <em>didn't</em> write CLRs? How does a CLR's "redo-only" nature make the recovery process idempotent and robust against repeated crashes?</p>
</li>
<li>
<p><strong>Checkpointing Frequency</strong>: What are the performance trade-offs between checkpointing very frequently versus very infrequently? Consider both normal runtime performance and the time it takes to recover after a crash.</p>
</li>
<li>
<p><strong>Programming Exercise</strong>: Add a new WAL record type. For example, a <code>HeapReclaim</code> record that logs the physical removal of a dead tuple by a vacuum process. To do this, you would need to:
a.  Add a variant to the <code>HeapRecordPayload</code> enum in <code>wal_record.rs</code>.
b.  Update the <code>codec</code> functions to handle its serialization.
c.  Decide what information the <code>HeapReclaim</code> record needs to contain.
d.  Implement the <code>redo</code> logic for this new record in the appropriate <code>ResourceManager</code>. What should happen when you redo a <code>HeapReclaim</code> record?</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="background-services"><a class="header" href="#background-services">Background Services</a></h1>
<p><code>src/background/</code> hosts the asynchronous workers that keep a database healthy: WAL
writers, checkpoints, buffer flushers, and MVCC vacuum. A central registry makes it easy
to start/stop workers together—ideal for teaching how background maintenance supports
foreground queries.</p>
<hr />
<h2 id="responsibilities-9"><a class="header" href="#responsibilities-9">Responsibilities</a></h2>
<ul>
<li>Start workers according to configuration (<code>IndexVacuumConfig</code>, <code>MvccVacuumConfig</code>,
<code>WalOptions</code>, etc.).</li>
<li>Define lightweight traits (<code>CheckpointWal</code>, <code>BufferMaintenance</code>, <code>TxnSnapshotOps</code>) so
workers can run without pulling in an async runtime.</li>
<li>Provide <code>BackgroundWorkers</code>, a registry that tracks <code>WorkerHandle</code>s and shuts them down
when <code>Database</code> drops.</li>
</ul>
<hr />
<h2 id="built-in-workers"><a class="header" href="#built-in-workers">Built-in Workers</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Worker</th><th>Trigger</th><th>Behavior</th></tr></thead><tbody>
<tr><td>WAL writer</td><td><code>wal_writer_interval_ms</code></td><td>Calls <code>WalManager::background_flush</code> to durably write log buffers.</td></tr>
<tr><td>Checkpoint</td><td><code>checkpoint_interval_ms</code></td><td>Captures dirty page / active txn tables and emits <code>Checkpoint</code> records to bound recovery.</td></tr>
<tr><td>Buffer writer</td><td><code>bg_writer_interval</code></td><td>Flushes dirty frames and nudges index vacuum when garbage accumulates.</td></tr>
<tr><td>MVCC vacuum</td><td><code>MvccVacuumConfig</code></td><td>Removes obsolete tuple versions once <code>safe_xmin</code> advances.</td></tr>
</tbody></table>
</div>
<p>Every worker registers itself with <code>BackgroundWorkers</code>; <code>shutdown_all()</code> ensures threads
exit cleanly during tests or process teardown.</p>
<hr />
<h2 id="interactions-11"><a class="header" href="#interactions-11">Interactions</a></h2>
<ul>
<li><strong>WalManager</strong> – WAL writer and checkpoint workers operate on <code>Arc&lt;dyn CheckpointWal&gt;</code>.</li>
<li><strong>BufferManager</strong> – background flushers inspect dirty frames and help checkpoints
capture consistent snapshots.</li>
<li><strong>TransactionManager</strong> – MVCC vacuum queries <code>TxnSnapshotOps</code> for <code>safe_xmin</code>.</li>
<li><strong>Catalog</strong> – index vacuum iterates <code>IndexRegistry</code> to locate candidate indexes.</li>
</ul>
<hr />
<h2 id="teaching-ideas-11"><a class="header" href="#teaching-ideas-11">Teaching Ideas</a></h2>
<ul>
<li>Tune <code>MvccVacuumConfig::batch_limit</code> and chart how quickly old tuple versions disappear.</li>
<li>Disable a worker in tests to show why unflushed WAL or missing checkpoints lengthen
recovery.</li>
<li>Enable <code>RUST_LOG=background=info</code> to trace how these tasks complement foreground load.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration--runtime-options"><a class="header" href="#configuration--runtime-options">Configuration &amp; Runtime Options</a></h1>
<p><code>src/config/</code> centralizes tunables used by <code>DatabaseOptions</code>, the CLI/HTTP front-ends, and
background workers. Keeping knobs in one place makes it easy to demonstrate how WAL,
buffering, or vacuum behavior changes under different settings.</p>
<hr />
<h2 id="key-types"><a class="header" href="#key-types">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DatabaseOptions</code></td><td>Top-level options when constructing a database (WAL config, default isolation, etc.).</td></tr>
<tr><td><code>WalOptions</code></td><td>WAL directory, segment size, flush strategy, writer interval, sync mode.</td></tr>
<tr><td><code>IndexVacuumConfig</code> / <code>MvccVacuumConfig</code></td><td>Frequency/batch settings for background cleanup tasks.</td></tr>
<tr><td><code>BufferPoolConfig</code></td><td>Optional overrides for pool size, TinyLFU, and replacement policy details.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<ul>
<li>CLI/HTTP front-ends parse env vars or config files into <code>DatabaseOptions</code> and pass them
to <code>Database::new_*</code>.</li>
<li>During <code>bootstrap_storage</code>, the database wires these options into <code>WalManager</code>,
<code>DiskScheduler</code>, and <code>BackgroundWorkers</code>.</li>
<li>Workers and execution components receive <code>Arc</code> references to the relevant configs so
they can adapt at runtime without global state.</li>
</ul>
<hr />
<h2 id="teaching-ideas-12"><a class="header" href="#teaching-ideas-12">Teaching Ideas</a></h2>
<ul>
<li>Toggle <code>WalOptions::synchronous_commit</code> to discuss commit latency vs durability.</li>
<li>Shrink the buffer pool to highlight eviction behavior under different replacement
policies.</li>
<li>Adjust <code>MvccVacuumConfig</code> intervals and measure how vacuum frequency affects foreground
write throughput.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="front-ends-cli--http"><a class="header" href="#front-ends-cli--http">Front-Ends (CLI / HTTP)</a></h1>
<p>The <code>bin/</code> directory contains the user-facing entry points. Both binaries embed the same
<code>Database</code> type, so they demonstrate how the core engine can power different UIs.</p>
<div class="table-wrapper"><table><thead><tr><th>Binary</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>client.rs</code></td><td>Interactive CLI (REPL) that reads SQL, executes it, and prints tabular output.</td></tr>
<tr><td><code>server.rs</code></td><td>HTTP + JSON API for integration tests or web UIs.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="cli-binclientrs"><a class="header" href="#cli-binclientrs">CLI (<code>bin/client.rs</code>)</a></h2>
<ul>
<li>Uses <code>rustyline</code> to provide history, multi-line editing, and familiar shell shortcuts.</li>
<li>Each command calls <code>database.run(sql)</code> and formats the resulting <code>Vec&lt;Tuple&gt;</code>.</li>
<li>Supports meta commands (e.g., <code>.tables</code>) that expose catalog metadata—great for
teaching how logical objects map to physical handles.</li>
</ul>
<h2 id="http-binserverrs"><a class="header" href="#http-binserverrs">HTTP (<code>bin/server.rs</code>)</a></h2>
<ul>
<li>Built with <code>axum</code>/<code>hyper</code> (depending on the current <code>Cargo.toml</code>), exposing endpoints such as:
<ul>
<li><code>POST /query</code> – run arbitrary SQL and return rows or an error payload.</li>
<li>Health/metrics endpoints—which you can extend in labs to surface background worker
status or buffer metrics.</li>
</ul>
</li>
<li>Configuration comes from <code>QUILL_DB_FILE</code>, <code>QUILL_HTTP_ADDR</code>, <code>PORT</code>, etc., mirroring
how production services inject settings.</li>
</ul>
<hr />
<h2 id="teaching-ideas-13"><a class="header" href="#teaching-ideas-13">Teaching Ideas</a></h2>
<ul>
<li>Extend the CLI with <code>\describe table</code> to practice catalog lookups.</li>
<li>Add transaction endpoints (BEGIN/COMMIT) to the HTTP server to demonstrate how
<code>SessionContext</code> scopes transactions per connection.</li>
<li>Combine CLI interaction with <code>RUST_LOG</code> tracing to walk through the entire query
lifecycle.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing--documentation"><a class="header" href="#testing--documentation">Testing &amp; Documentation</a></h1>
<p>QuillSQL is intended for teaching, so the repo invests heavily in examples and automated
verification. The <code>tests/</code> tree and this mdBook work together to illustrate every module.</p>
<hr />
<h2 id="test-suite"><a class="header" href="#test-suite">Test Suite</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Location</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tests/sql_example/*.slt</code></td><td><a href="https://www.sqlite.org/sqllogictest.html">sqllogictest</a> suites covering DDL, DML, transactions, and indexes.</td></tr>
<tr><td><code>tests/transaction_tests.rs</code></td><td>Rust unit tests that stress MVCC visibility, lock conflicts, and isolation semantics.</td></tr>
<tr><td><code>tests/storage_*</code></td><td>Component tests for heap/index/buffer internals—perfect references for lab exercises.</td></tr>
</tbody></table>
</div>
<p>Common commands:</p>
<pre><code class="language-bash">cargo test -q
# focused run
cargo test tests::transaction_tests::repeatable_read_sees_consistent_snapshot_after_update -- --nocapture
</code></pre>
<p>For long-running suites, wrap with <code>timeout</code> to guard against hangs.</p>
<hr />
<h2 id="documentation-mdbook"><a class="header" href="#documentation-mdbook">Documentation (mdBook)</a></h2>
<ul>
<li>The <code>docs/</code> directory is an mdBook; run <code>mdbook serve docs</code> to browse locally.</li>
<li>Each module, including this page, has a dedicated chapter so instructors can teach
subsystem by subsystem.</li>
<li>Anchor chapters such as <code>architecture.md</code>, <code>transactions.md</code>, and <code>wal.md</code> walk through
end-to-end flows and subsystem deep dives.</li>
</ul>
<hr />
<h2 id="teaching-ideas-14"><a class="header" href="#teaching-ideas-14">Teaching Ideas</a></h2>
<ul>
<li>Require sqllogictest additions alongside code changes to reinforce “tests as docs”.</li>
<li>Use the mdBook site during lectures to connect diagrams with source files.</li>
<li>Assign “doc walk-through” tasks where students extend diagrams or add experiment
instructions to existing chapters.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>



        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
